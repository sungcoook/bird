{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # colab 기준으로 돌리는 경우, 아래처럼 라이브러리를 설치해주셔야 합니다.\n",
    "# # 코드는 RTX-A4000 환경이었는데, T4에서 잘될지 모르겠네요.\n",
    "# # A100이나 V100에서 돌리길 권장합니다.\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# import os\n",
    "# os.makedirs('/tmp/project', exist_ok=True)\n",
    "# os.chdir('/tmp/project')\n",
    "# print( os.getcwd() )\n",
    "# if not os.path.exists('/tmp/project/train.csv'):\n",
    "#     !cp /content/drive/MyDrive/Colab_Notebooks/dacon/2024_저해상도조류이미지/open.zip /tmp/project\n",
    "#     !unzip -o -q open.zip\n",
    "#     !rm open.zip\n",
    "#     # 추가 모듈 설치\n",
    "#     !sudo apt-get install -y libmagickwand-dev\n",
    "#     !pip install wandb timm wand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "k95fPjnRSjV0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gooruem/anaconda3/envs/BIRD/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-11-19 05:45:08.423993: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-19 05:45:08.424063: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-19 05:45:08.425201: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-19 05:45:08.433084: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-19 05:45:10.738413: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 05:45:13 [INFO] program started\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "from glob import glob\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torchvision.transforms import v2\n",
    "import albumentations as A\n",
    "import cv2\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import Swinv2Model, ConvNextV2Model, AutoModel\n",
    "import timm\n",
    "from PIL import Image\n",
    "\n",
    "torch.set_float32_matmul_precision('high')  # or 'medium' | 'high'\n",
    "#pytorch에서 float32 타입의 행렬 곱셈 연산의 정확도와 성능 간의 균형을 조정하기 위함\n",
    "#medium => 속도를 우선, 일부 연산에서 낮은 정확도를 허용하여 곱셈의 속도를 높임\n",
    "#high => 정확도를 우선, 계산 속도가 느려지지만 연산 결과의 정밀도가 높아짐.\n",
    "# os.environ['WANDB_API_KEY']='xxxxx'\n",
    "# os.environ['WANDB_MODE']='online'\n",
    "# os.environ['WANDB_PROJECT']='basslibrary240210'\n",
    "os.environ['WANDB_MODE']='offline'\n",
    "\n",
    "######## logger ########\n",
    "import sys, logging, IPython\n",
    "logger = logging.getLogger()\n",
    "logging.basicConfig( handlers=[ logging.StreamHandler(stream=sys.stdout), logging.handlers.RotatingFileHandler(filename='run.log', mode='a', maxBytes=512000, backupCount=4) ] )\n",
    "logging_fomatter = logging.Formatter( '%(asctime)s [%(levelname)-4.4s] %(message)s', datefmt='%m/%d %H:%M:%S' )\n",
    "_ = [ h.setFormatter(logging_fomatter) for h in logger.handlers ]\n",
    "logger.setLevel(logging.INFO)\n",
    "def showtraceback(self, *args, **kwargs):\n",
    "    logger.exception('-------Exception----------')\n",
    "IPython.core.interactiveshell.InteractiveShell.showtraceback = showtraceback\n",
    "logger.info('program started')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n4qX0V8CSjTB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 05:45:13 [INFO] {'SEED': 42, 'N_SPLIT': 5, 'LABEL_SMOOTHING': 0.05, 'OPTIMIZER': 'AdamW', 'INTERPOLATION': 'robidouxsharp', 'PRECISION': '16', 'MODEL_NAME': 'timm/eva_large_patch14_336.in22k_ft_in22k_in1k', 'IMG_SIZE': 336, 'BATCH_SIZE': 16, 'LR': [1e-05, 1e-07], 'IMG_TRAIN_SIZE': 336}\n"
     ]
    }
   ],
   "source": [
    "CFG = {}\n",
    "CFG['SEED'] = 42\n",
    "CFG['N_SPLIT'] = 5\n",
    "CFG['LABEL_SMOOTHING'] = 0.11\n",
    "CFG['OPTIMIZER'] = 'AdamW'\n",
    "CFG['INTERPOLATION'] = 'robidouxsharp'\n",
    "CFG['PRECISION'] = '16'\n",
    "# #----------------------------------\n",
    "# # [9842]\n",
    "CFG['MODEL_NAME'] = \"timm/eva_large_patch14_336.in22k_ft_in22k_in1k\"\n",
    "CFG['IMG_SIZE'] = 336\n",
    "CFG['BATCH_SIZE'] = 16 ## 16//16G\n",
    "CFG['LR'] = [ 0.25e-5 * np.sqrt(CFG['BATCH_SIZE']), 1e-7 ]\n",
    "# # ----------------------------------\n",
    "# # [0. --[9836][9842x2]\n",
    "# [0.9811,0.9825,0.9811,0.9819,0.9837]\n",
    "# CFG['MODEL_NAME'] = \"timm/eva_large_patch14_196.in22k_ft_in22k_in1k\"\n",
    "# CFG['IMG_SIZE'] = 196\n",
    "# # CFG['IMG_TRAIN_SIZE'] = 196 * 2\n",
    "# CFG['BATCH_SIZE'] = 8 ## 48/16G(ema), 16/8G\n",
    "# CFG['LR'] = [ 0.25e-5 * np.sqrt(CFG['BATCH_SIZE']), 1e-6 ]\n",
    "# # ----------------------------------\n",
    "# [0.9768, 0.9707, 0.9714, 0.9791, 0.9724 ]\n",
    "# CFG['MODEL_NAME'] = \"timm/convnextv2_large.fcmae_ft_in22k_in1k\" ## 288 \n",
    "# # CFG['MODEL_NAME'] = \"facebook/convnextv2-large-22k-224\"\n",
    "# CFG['IMG_SIZE'] = 288\n",
    "# CFG['BATCH_SIZE'] = 16  # 6/8G, 16/16G\n",
    "# CFG['PRECISION'] = '16'\n",
    "# CFG['LR'] = [ 0.25e-5 * np.sqrt(CFG['BATCH_SIZE']), 1e-7 ]\n",
    "# #----------------------------------\n",
    "# ## best_score=0.9699\n",
    "# ## A4000: [9737]\n",
    "# CFG['MODEL_NAME'] = \"timm/swinv2_large_window12_192.ms_in22k\"\n",
    "# CFG['IMG_SIZE'] = 192\n",
    "# CFG['BATCH_SIZE'] = 40 ## 40/16\n",
    "# CFG['LR'] = 0.25e-5 * np.sqrt(CFG['BATCH_SIZE'])\n",
    "# # #----------------------------------\n",
    "# # best_score=0.9805\n",
    "# [0.9818,0.9815,0.9803,0.9825,0.9813]\n",
    "# CFG['MODEL_NAME'] = \"timm/beitv2_large_patch16_224.in1k_ft_in22k_in1k\"\n",
    "# CFG['IMG_SIZE'] = 224\n",
    "# CFG['BATCH_SIZE'] = 48 ## 48//16G(ema), 14//8G memory..\n",
    "# CFG['LR'] = [ 0.25e-5 * np.sqrt(CFG['BATCH_SIZE']), 1e-6 ]\n",
    "# #----------------------------------\n",
    "# [0.9742, ]\n",
    "# CFG['MODEL_NAME'] = \"timm/deit3_large_patch16_224.fb_in22k_ft_in1k\"    ## 304MB\n",
    "# CFG['IMG_SIZE'] = 224\n",
    "# CFG['BATCH_SIZE'] = 24 ## 48//16G, 4//8G memory..\n",
    "# CFG['LR'] = [ 0.25e-5 * np.sqrt(CFG['BATCH_SIZE']), 1e-7 ]\n",
    "# #----------------------------------\n",
    "\n",
    "######################################\n",
    "if 'IMG_TRAIN_SIZE' not in CFG:\n",
    "    CFG['IMG_TRAIN_SIZE'] = CFG['IMG_SIZE']\n",
    "logger.info(CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 05:45:13 [INFO] cuda\n"
     ]
    }
   ],
   "source": [
    "assert torch.cuda.is_available()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.set_default_device(device) # torch.?(device=dvice)라고 명시해주지 않아도 전역적으로 cuda를 사용하도록 설정.\n",
    "logger.info(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 05:45:14 [INFO] seed_everything : 42\n"
     ]
    }
   ],
   "source": [
    "def seed_everything(seed):\n",
    "    logger.info(f'seed_everything : {seed}')\n",
    "\n",
    "    import random, os\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "kCL6U72NSxNp"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_path_list, label_list, load_img_size, shuffle=False, transforms=None, interpolation='robidouxsharp' ):\n",
    "        self.df = pd.DataFrame({'img_path_list': img_path_list})\n",
    "        self.interpolation = interpolation\n",
    "        self.load_img_size = load_img_size\n",
    "        logger.info(f'load_img_size={load_img_size}')\n",
    "        if label_list is not None:\n",
    "            self.df['label_list'] = label_list\n",
    "        if shuffle:\n",
    "            self.df = self.df.sample(frac=1.0).reset_index(drop=True)\n",
    "        self.transforms = transforms\n",
    "\n",
    "    # numpy or PIL Image => PIL Image\n",
    "    def get_interpolated_image(self, img, new_image_size):\n",
    "        if self.interpolation == 'pil_lanczos':\n",
    "            if isinstance(img, np.ndarray ):\n",
    "                img = Image.fromarray(img)\n",
    "            return img.resize( (new_image_size, new_image_size), Image.LANCZOS )\n",
    "        elif self.interpolation == 'cv2_lanczos4':\n",
    "            if not isinstance(img, np.ndarray ):\n",
    "                img = np.array(img)\n",
    "            import cv2\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "            img = cv2.resize(src, (new_image_size, new_image_size), interpolation=cv2.INTER_LANCZOS4) # 픽셀 크기 지정\n",
    "            img = cv2.cvtColor(np.array(img), cv2.COLOR_BGR2RGB)\n",
    "            return Image.fromarray(img)\n",
    "        else:\n",
    "            if not isinstance(img, np.ndarray ):\n",
    "                img = np.array(img)\n",
    "            from wand import image\n",
    "            with image.Image.from_array(img) as src:\n",
    "                src.resize( new_image_size, new_image_size, filter=self.interpolation )\n",
    "                return Image.fromarray(np.array(src))\n",
    "                \n",
    "    # path => PIL Image\n",
    "    def get_image_from_index(self, index, img_size ):\n",
    "        img_path = self.df.img_path_list[index]\n",
    "        fname = img_path.replace('./','').split('.')[0] + '.png'\n",
    "        full_fname = f'img_cached/{img_size}_{self.interpolation}/{fname}'\n",
    "        if os.path.exists(full_fname):\n",
    "            img = Image.open(full_fname)\n",
    "        else:            \n",
    "            fname_path = '/'.join(full_fname.split('/')[:-1])\n",
    "            os.makedirs(fname_path, exist_ok = True)\n",
    "            img = self.get_interpolated_image(Image.open(img_path), img_size )\n",
    "            img.save( full_fname )\n",
    "        return img\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = self.get_image_from_index( index, self.load_img_size )\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image)\n",
    "        if 'label_list' in self.df.columns:\n",
    "            label = self.df.label_list[index]\n",
    "            return { 'pixel_values': image, 'label': label }\n",
    "        else:\n",
    "            return { 'pixel_values': image }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ref: https://github.com/katsura-jp/pytorch-cosine-annealing-with-warmup/blob/master/cosine_annealing_warmup/scheduler.py\n",
    "import math\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "class CosineAnnealingWarmupRestarts(_LRScheduler):\n",
    "    \"\"\"\n",
    "        optimizer (Optimizer): Wrapped optimizer.\n",
    "        first_cycle_steps (int): First cycle step size.\n",
    "        cycle_mult(float): Cycle steps magnification. Default: -1.\n",
    "        max_lr(float): First cycle's max learning rate. Default: 0.1.\n",
    "        min_lr(float): Min learning rate. Default: 0.001.\n",
    "        warmup_steps(int): Linear warmup step size. Default: 0.\n",
    "        gamma(float): Decrease rate of max learning rate by cycle. Default: 1.\n",
    "        last_epoch (int): The index of last epoch. Default: -1.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self,\n",
    "                 optimizer : torch.optim.Optimizer,\n",
    "                 first_cycle_steps : int,\n",
    "                 cycle_mult : float = 1.,\n",
    "                 max_lr : float = 1e-5,\n",
    "                 min_lr : float = 1e-10,\n",
    "                 warmup_steps : int = 0,\n",
    "                 gamma : float = 1.,\n",
    "                 last_epoch : int = -1\n",
    "        ):\n",
    "        assert warmup_steps < first_cycle_steps\n",
    "        \n",
    "        self.first_cycle_steps = first_cycle_steps # first cycle step size\n",
    "        self.cycle_mult = cycle_mult # cycle steps magnification\n",
    "        self.base_max_lr = max_lr # first max learning rate\n",
    "        self.max_lr = max_lr # max learning rate in the current cycle\n",
    "        self.min_lr = min_lr # min learning rate\n",
    "        self.warmup_steps = warmup_steps # warmup step size\n",
    "        self.gamma = gamma # decrease rate of max learning rate by cycle\n",
    "        \n",
    "        self.cur_cycle_steps = first_cycle_steps # first cycle step size\n",
    "        self.cycle = 0 # cycle count\n",
    "        self.step_in_cycle = last_epoch # step size of the current cycle\n",
    "        \n",
    "        super(CosineAnnealingWarmupRestarts, self).__init__(optimizer, last_epoch)\n",
    "        \n",
    "        # set learning rate min_lr\n",
    "        self.init_lr()\n",
    "    \n",
    "    def init_lr(self):\n",
    "        self.base_lrs = []\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = self.min_lr\n",
    "            self.base_lrs.append(self.min_lr)\n",
    "    \n",
    "    def get_lr(self):\n",
    "        if self.step_in_cycle == -1:\n",
    "            return self.base_lrs\n",
    "        elif self.step_in_cycle < self.warmup_steps:\n",
    "            return [(self.max_lr - base_lr)*self.step_in_cycle / self.warmup_steps + base_lr for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            return [base_lr + (self.max_lr - base_lr) \\\n",
    "                    * (1 + math.cos(math.pi * (self.step_in_cycle-self.warmup_steps) \\\n",
    "                                    / (self.cur_cycle_steps - self.warmup_steps))) / 2\n",
    "                    for base_lr in self.base_lrs]\n",
    "\n",
    "    def step(self, epoch=None):\n",
    "        if epoch is None:\n",
    "            epoch = self.last_epoch + 1\n",
    "            self.step_in_cycle = self.step_in_cycle + 1\n",
    "            if self.step_in_cycle >= self.cur_cycle_steps:\n",
    "                self.cycle += 1\n",
    "                self.step_in_cycle = self.step_in_cycle - self.cur_cycle_steps\n",
    "                self.cur_cycle_steps = int((self.cur_cycle_steps - self.warmup_steps) * self.cycle_mult) + self.warmup_steps\n",
    "        else:\n",
    "            if epoch >= self.first_cycle_steps:\n",
    "                if self.cycle_mult == 1.:\n",
    "                    self.step_in_cycle = epoch % self.first_cycle_steps\n",
    "                    self.cycle = epoch // self.first_cycle_steps\n",
    "                else:\n",
    "                    n = int(math.log((epoch / self.first_cycle_steps * (self.cycle_mult - 1) + 1), self.cycle_mult))\n",
    "                    self.cycle = n\n",
    "                    self.step_in_cycle = epoch - int(self.first_cycle_steps * (self.cycle_mult ** n - 1) / (self.cycle_mult - 1))\n",
    "                    self.cur_cycle_steps = self.first_cycle_steps * self.cycle_mult ** (n)\n",
    "            else:\n",
    "                self.cur_cycle_steps = self.first_cycle_steps\n",
    "                self.step_in_cycle = epoch\n",
    "                \n",
    "        self.max_lr = self.base_max_lr * (self.gamma**self.cycle)\n",
    "        self.last_epoch = math.floor(epoch)\n",
    "        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n",
    "            param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TfQfZc6lSxJD"
   },
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.clf = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.LazyLinear(25)\n",
    "            )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = x.pooler_output\n",
    "        if self.clf:\n",
    "            x = self.clf(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "VoWIJtWISjOC"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./train.csv')\n",
    "le = LabelEncoder()\n",
    "train_df['class'] = le.fit_transform(train_df['label'])\n",
    "\n",
    "# from sklearn.utils import resample\n",
    "\n",
    "# df = pd.read_csv('./train.csv')\n",
    "\n",
    "# target_sample_size = 5000\n",
    "# unique_labels = df['label'].nunique()\n",
    "# samples_per_label = target_sample_size // unique_labels\n",
    "\n",
    "# train_df = (\n",
    "#     df.groupby('label', group_keys=False)\n",
    "#     .apply(lambda x: resample(x, n_samples=min(samples_per_label, len(x)), random_state=42))\n",
    "# )\n",
    "\n",
    "# train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "# le = LabelEncoder()\n",
    "# train_df['class'] = le.fit_transform(train_df['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "vj2Tb6MuTL5b"
   },
   "outputs": [],
   "source": [
    "if not len(train_df) == len(os.listdir('./train')):\n",
    "    raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ETmPNpAqSjLe"
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=CFG['N_SPLIT'], random_state=CFG['SEED'], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = CFG['IMG_SIZE']\n",
    "\n",
    "train_transform_list = [\n",
    "    # v2.RandomHorizontalFlip(), ## eva모델등에서는 성능향상이 없음. 오히려 성능떨어짐.\n",
    "    v2.TrivialAugmentWide(interpolation=v2.InterpolationMode.BICUBIC), \n",
    "    v2.RandomErasing(),\n",
    "    v2.Resize(size=(image_size, image_size), interpolation=v2.InterpolationMode.LANCZOS, antialias=True),\n",
    "    v2.ToImage(), v2.ToDtype( torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "]\n",
    "if CFG['IMG_SIZE'] == CFG['IMG_TRAIN_SIZE']:\n",
    "    train_transform_list = [ a for a in train_transform_list if not isinstance(a, v2.Resize) ]\n",
    "train_transform = v2.Compose(train_transform_list )\n",
    "test_transform = v2.Compose( [\n",
    "    v2.ToImage(), v2.ToDtype( torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "class_weight = torch.FloatTensor( compute_class_weight('balanced', classes=train_df.label.sort_values().unique(), y=train_df.label ) )\n",
    "\n",
    "def train(model, optimizer, train_loader, val_loader, scheduler, device, validation_steps = 0.25, logging_steps = 10, use_amp=True, filename=''):\n",
    "    logger.info(f'{use_amp=}')\n",
    "\n",
    "    model.to(device)\n",
    "    best_score = 0\n",
    "    best_loss  = 1000\n",
    "    best_model = None\n",
    "    MAX_PATIENCE = 5\n",
    "    best_patience = MAX_PATIENCE\n",
    "    loss_fn = nn.CrossEntropyLoss( weight=class_weight, label_smoothing=CFG['LABEL_SMOOTHING'], reduction='mean' ).to(device)\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "    checkpoint_filenames = []\n",
    "\n",
    "    max_steps = len(train_loader)\n",
    "    if not isinstance(validation_steps, int):\n",
    "        validation_steps = int(max_steps * validation_steps)  ## 절사..\n",
    "    max_steps = (max_steps//validation_steps)*validation_steps\n",
    "    \n",
    "    # ema 모델은 모델의 weight 한벌을 가지고 있어, 메모리 사용량도 확인해야 함..\n",
    "    ema_model = None  ## 의미가 없을 듯..\n",
    "    ema_decay = np.power(np.e, np.log(0.5)/(validation_steps*MAX_PATIENCE))\n",
    "    ema_model = torch.optim.swa_utils.AveragedModel(model, multi_avg_fn=torch.optim.swa_utils.get_ema_multi_avg_fn(ema_decay))\n",
    "                         \n",
    "    for epoch in range(1, 1000):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        pbar_postfix = {}\n",
    "\n",
    "        pbar = tqdm(train_loader, desc=f'Epoch {epoch}')\n",
    "        for i, batch in enumerate(pbar):\n",
    "            if i >= max_steps:\n",
    "                continue\n",
    "            steps = i+1\n",
    "            \n",
    "            if use_amp:\n",
    "                with torch.autocast(device_type=device, dtype=torch.float16, enabled=use_amp):\n",
    "                    output = model(batch['pixel_values'])\n",
    "                    loss = loss_fn(output, batch['label'])\n",
    "                scaler.scale(loss).backward()\n",
    "\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.1)\n",
    "                \n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "            else:\n",
    "                output = model(batch['pixel_values'])\n",
    "                loss = loss_fn(output, batch['label'])\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "            loss = None\n",
    "            output = None\n",
    "            batch = None\n",
    "            \n",
    "            if ema_model is not None:\n",
    "                ema_model.update_parameters(model)\n",
    "            \n",
    "\n",
    "            if steps % logging_steps == 0:\n",
    "                pbar_postfix.update({\n",
    "                    't_loss0': train_loss[-1], \n",
    "                    'lr': optimizer.param_groups[0][\"lr\"]\n",
    "                } )\n",
    "                pbar.set_postfix( pbar_postfix )\n",
    "                run.log({\n",
    "                    \"epoch\": epoch, \n",
    "                    \"step\": steps,\n",
    "                    \"train\":{\"loss\": train_loss[-1]}, \n",
    "                    \"lr\": optimizer.param_groups[0][\"lr\"]\n",
    "                }, step=(epoch-1)*max_steps+steps)\n",
    "                \n",
    "            if steps % validation_steps == 0:\n",
    "                _val_loss, _val_score = validation(model, loss_fn, val_loader, device, use_amp)\n",
    "                _train_loss = np.mean(train_loss)\n",
    "                \n",
    "                best_score_mark = '*' if best_score < _val_score else ' '\n",
    "                best_loss_mark = '*' if best_loss > _val_loss else ' '\n",
    "                pbar_postfix.update({\n",
    "                    'lr': optimizer.param_groups[0][\"lr\"], \n",
    "                    't_loss': _train_loss,\n",
    "                    'v_loss': _val_loss, \n",
    "                    'v_f1': _val_score \n",
    "                })\n",
    "                pbar.set_postfix( pbar_postfix )\n",
    "                logger.info(f'eps={epoch:d}, lr={optimizer.param_groups[0][\"lr\"]:.3g}, t_loss={_train_loss:.4f}, v_loss={_val_loss:.4f}{best_loss_mark}, v_f1={_val_score:.4f}{best_score_mark}')\n",
    "                run.log({\n",
    "                    \"epoch\": epoch, \"step\": steps,\n",
    "                    \"train\":{\"avg_loss\": _train_loss}, \n",
    "                    \"valid\": { \"loss\": _val_loss, \"score\": _val_score},\n",
    "                    \"lr\": optimizer.param_groups[0][\"lr\"] \n",
    "                }, step=(epoch-1)*max_steps+steps)\n",
    "                \n",
    "                if best_score < _val_score:\n",
    "                    best_score = _val_score\n",
    "                    best_model = model\n",
    "                    best_patience = MAX_PATIENCE\n",
    "                    ## saving..\n",
    "                    if filename is not None and len(filename) != 0:\n",
    "                        checkpoint_filenames.append(\n",
    "                            filename.format(epoch=epoch, val_loss=_val_loss, val_score=_val_score) + '.ckpt' )\n",
    "                        if best_score > 0.9750:\n",
    "                            os.makedirs(os.path.dirname(checkpoint_filenames[-1]), exist_ok=True)\n",
    "                            torch.save( {\"model\": model.state_dict() }, checkpoint_filenames[-1] )\n",
    "                            logger.info( f'{checkpoint_filenames[-1]} : saved.' )\n",
    "                            _ = [ os.path.exists(fname) and os.remove(fname) for fname in checkpoint_filenames[:-1] ]\n",
    "                            checkpoint_filenames = checkpoint_filenames[-1:]\n",
    "                    \n",
    "                    ## 추가적으로 비교함..\n",
    "                    if best_loss > _val_loss:\n",
    "                        best_loss = _val_loss\n",
    "                elif best_loss > _val_loss:\n",
    "                    best_loss = _val_loss\n",
    "                    best_patience = MAX_PATIENCE\n",
    "                elif best_patience > 0:\n",
    "                    best_patience -= 1\n",
    "                else:\n",
    "                    logger.info(f'NO_MORE_TRAINING, {best_score=:.4f}')\n",
    "                    if ema_model is not None:\n",
    "                        # ## EMA --------------------\n",
    "                        torch.optim.swa_utils.update_bn(train_loader, ema_model, device )\n",
    "                        ema_val_loss, ema_val_score = validation(ema_model, loss_fn, val_loader, device, use_amp)\n",
    "                        logger.info(f'EMA ::: ema_v_loss={ema_val_loss:.4f}, ema_v_f1={ema_val_score:.4f}')\n",
    "                        run.log({'ema_v_loss': ema_val_loss, 'ema_v_f1': ema_val_score })\n",
    "                        \n",
    "                        save_filename = filename.format(epoch=epoch, val_loss=ema_val_loss, val_score=ema_val_score) + '-ema.ckpt'\n",
    "                        torch.save( {\"model\": ema_model.state_dict() }, save_filename )\n",
    "                        logger.info( f'{save_filename} : (ema) saved.' )\n",
    "                        # ##========================\n",
    "                    if not os.path.exists(checkpoint_filenames[-1]):\n",
    "                        os.makedirs(os.path.dirname(checkpoint_filenames[-1]), exist_ok=True)\n",
    "                        torch.save( {\"model\": best_model.state_dict() }, checkpoint_filenames[-1] )\n",
    "                        logger.info( f'{checkpoint_filenames[-1]} : saved.' )\n",
    "                        _ = [ os.path.exists(fname) and os.remove(fname) for fname in checkpoint_filenames[:-1] ]\n",
    "                        checkpoint_filenames = checkpoint_filenames[-1:]\n",
    "                    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, loss_fn, val_loader, device, use_amp):\n",
    "    model = model.to(device)\n",
    "    save_training = model.training\n",
    "    model.eval()\n",
    "    \n",
    "    val_loss = []\n",
    "    preds, true_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader):\n",
    "            true_labels += batch['label'].detach().cpu().numpy().tolist()\n",
    "            with torch.autocast(device_type=device, dtype=torch.float16, enabled=use_amp):\n",
    "                pred = model(batch['pixel_values'])\n",
    "                loss = loss_fn(pred, batch['label'])\n",
    "            preds += pred.detach().argmax(1).cpu().numpy().tolist()\n",
    "            val_loss.append(loss.item())\n",
    "        \n",
    "        _val_loss = np.mean(val_loss)\n",
    "        _val_score = f1_score(true_labels, preds, average='macro')\n",
    "    ## return_to_train..\n",
    "    if save_training:\n",
    "        model.train()\n",
    "    return _val_loss, _val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model, test_loader, device):\n",
    "    model = model.to(device)\n",
    "    save_training = model.training\n",
    "    model.eval()\n",
    "    preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader):\n",
    "            pixel_values = batch['pixel_values'].to(device)            \n",
    "            pred = model(pixel_values)  ## F.softmax(output) ## 의미는 없을 듯.\n",
    "            preds += pred.detach().cpu().numpy().tolist()\n",
    "    if save_training:\n",
    "        model.train()\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_name):\n",
    "    import timm\n",
    "    from transformers import AutoModel, AutoModelForImageClassification, AutoConfig\n",
    "\n",
    "    logger.info(f'create_model: {model_name}')\n",
    "    if '/' not in model_name:\n",
    "        model_name = 'timm/' + model_name\n",
    "        \n",
    "    if model_name.startswith('./'):\n",
    "        import nextvit\n",
    "        model = CustomModel( timm.create_model('nextvit_large', pretrained=True, checkpoint_path=model_name) )\n",
    "    elif model_name.startswith('facebook/hiera_'):\n",
    "        from hiera import Hiera  ## pip install hiera-transformer\n",
    "        model = CustomModel( Hiera.from_pretrained(model_name) )\n",
    "    elif model_name.startswith('timm/'):\n",
    "        model = CustomModel( timm.create_model( model_name, pretrained=True ) )\n",
    "    else:\n",
    "        model = CustomModel( AutoModel.from_pretrained(model_name) )\n",
    "    model.eval()\n",
    "    model( torch.rand((1,3,CFG['IMG_SIZE'],CFG['IMG_SIZE'])).type(torch.float32) ) ## initalize_lazyLinear..\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ZvWhUDQ1SjI_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 05:45:17 [INFO] fold_idx=0 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 05:45:17 [INFO] load_img_size=336\n",
      "11/19 05:45:17 [INFO] load_img_size=336\n",
      "11/19 05:45:17 [INFO] create_model: timm/eva_large_patch14_336.in22k_ft_in22k_in1k\n",
      "11/19 05:45:18 [INFO] Loading pretrained weights from Hugging Face hub (timm/eva_large_patch14_336.in22k_ft_in22k_in1k)\n",
      "11/19 05:45:18 [INFO] [timm/eva_large_patch14_336.in22k_ft_in22k_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "11/19 05:45:20 [INFO] use_amp=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_181389/2507413745.py:14: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
      "100%|██████████| 99/99 [00:59<00:00,  1.65it/s]  1.01s/it, t_loss0=0.607, lr=1.8e-7] \n",
      "Epoch 1:  25%|██▍       | 197/792 [04:25<10:03,  1.01s/it, t_loss0=0.607, lr=1.86e-5, t_loss=1.18, v_loss=0.508, v_f1=0.959]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 05:49:46 [INFO] eps=1, lr=1.86e-05, t_loss=1.1842, v_loss=0.5085*, v_f1=0.9586*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:59<00:00,  1.67it/s]  1.02s/it, t_loss0=0.372, lr=1.42e-7, t_loss=1.18, v_loss=0.508, v_f1=0.959]  \n",
      "Epoch 1:  50%|████▉     | 395/792 [08:48<06:45,  1.02s/it, t_loss0=0.372, lr=1.73e-5, t_loss=0.914, v_loss=0.457, v_f1=0.97]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 05:54:08 [INFO] eps=1, lr=1.73e-05, t_loss=0.9142, v_loss=0.4571*, v_f1=0.9696*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:59<00:00,  1.66it/s]  1.03s/it, t_loss0=0.517, lr=1.17e-7, t_loss=0.914, v_loss=0.457, v_f1=0.97]  \n",
      "Epoch 1:  75%|███████▍  | 593/792 [13:11<03:25,  1.03s/it, t_loss0=0.517, lr=1.61e-5, t_loss=0.809, v_loss=0.441, v_f1=0.973]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 05:58:31 [INFO] eps=1, lr=1.61e-05, t_loss=0.8085, v_loss=0.4411*, v_f1=0.9726*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:59<00:00,  1.65it/s]  1.06s/it, t_loss0=0.518, lr=1.04e-7, t_loss=0.809, v_loss=0.441, v_f1=0.973]  \n",
      "Epoch 1: 100%|█████████▉| 791/792 [17:43<00:01,  1.06s/it, t_loss0=0.518, lr=1.5e-5, t_loss=0.75, v_loss=0.436, v_f1=0.975]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 06:03:03 [INFO] eps=1, lr=1.5e-05, t_loss=0.7503, v_loss=0.4361*, v_f1=0.9748*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 792/792 [17:43<00:00,  1.34s/it, t_loss0=0.518, lr=1.5e-5, t_loss=0.75, v_loss=0.436, v_f1=0.975]\n",
      "100%|██████████| 99/99 [00:59<00:00,  1.67it/s]  1.04s/it, t_loss0=0.567, lr=1.6e-7] \n",
      "Epoch 2:  25%|██▍       | 197/792 [04:28<10:20,  1.04s/it, t_loss0=0.567, lr=1.39e-5, t_loss=0.522, v_loss=0.433, v_f1=0.973]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 06:07:31 [INFO] eps=2, lr=1.39e-05, t_loss=0.5222, v_loss=0.4330*, v_f1=0.9731 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:59<00:00,  1.65it/s]  1.01s/it, t_loss0=0.445, lr=1.31e-7, t_loss=0.522, v_loss=0.433, v_f1=0.973]  \n",
      "Epoch 2:  50%|████▉     | 395/792 [08:52<06:42,  1.01s/it, t_loss0=0.445, lr=1.29e-5, t_loss=0.529, v_loss=0.425, v_f1=0.976]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 06:11:56 [INFO] eps=2, lr=1.29e-05, t_loss=0.5287, v_loss=0.4247*, v_f1=0.9758*\n",
      "11/19 06:11:58 [INFO] ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in1k-fold_idx=0-epoch=02-val_loss=0.4247-val_score=0.9758.ckpt : saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:59<00:00,  1.66it/s]  1.04s/it, t_loss0=0.387, lr=1.13e-7, t_loss=0.529, v_loss=0.425, v_f1=0.976]  \n",
      "Epoch 2:  75%|███████▍  | 593/792 [13:19<03:27,  1.04s/it, t_loss0=0.387, lr=1.2e-5, t_loss=0.527, v_loss=0.424, v_f1=0.974] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 06:16:23 [INFO] eps=2, lr=1.2e-05, t_loss=0.5271, v_loss=0.4237*, v_f1=0.9743 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:59<00:00,  1.66it/s]  1.02s/it, t_loss0=0.443, lr=1.03e-7, t_loss=0.527, v_loss=0.424, v_f1=0.974] \n",
      "Epoch 2: 100%|█████████▉| 791/792 [17:43<00:01,  1.02s/it, t_loss0=0.443, lr=1.12e-5, t_loss=0.525, v_loss=0.418, v_f1=0.978]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 06:20:47 [INFO] eps=2, lr=1.12e-05, t_loss=0.5246, v_loss=0.4183*, v_f1=0.9785*\n",
      "11/19 06:20:49 [INFO] ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in1k-fold_idx=0-epoch=02-val_loss=0.4183-val_score=0.9785.ckpt : saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 792/792 [17:46<00:00,  1.35s/it, t_loss0=0.443, lr=1.12e-5, t_loss=0.525, v_loss=0.418, v_f1=0.978]\n",
      "100%|██████████| 99/99 [00:59<00:00,  1.67it/s]  1.04s/it, t_loss0=0.351, lr=1.45e-7]\n",
      "Epoch 3:  25%|██▍       | 197/792 [04:30<10:21,  1.04s/it, t_loss0=0.351, lr=1.04e-5, t_loss=0.501, v_loss=0.418, v_f1=0.977]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 06:25:20 [INFO] eps=3, lr=1.04e-05, t_loss=0.5009, v_loss=0.4178*, v_f1=0.9772 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:00<00:00,  1.65it/s]  1.03s/it, t_loss0=0.444, lr=1.23e-7, t_loss=0.501, v_loss=0.418, v_f1=0.977]  \n",
      "Epoch 3:  50%|████▉     | 395/792 [09:00<06:48,  1.03s/it, t_loss0=0.444, lr=9.68e-6, t_loss=0.491, v_loss=0.417, v_f1=0.979]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 06:29:50 [INFO] eps=3, lr=9.68e-06, t_loss=0.4914, v_loss=0.4174*, v_f1=0.9792*\n",
      "11/19 06:29:52 [INFO] ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in1k-fold_idx=0-epoch=03-val_loss=0.4174-val_score=0.9792.ckpt : saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:59<00:00,  1.65it/s]  1.03s/it, t_loss0=0.478, lr=1.1e-7, t_loss=0.491, v_loss=0.417, v_f1=0.979]   \n",
      "Epoch 3:  75%|███████▍  | 593/792 [13:35<03:25,  1.03s/it, t_loss0=0.478, lr=9e-6, t_loss=0.492, v_loss=0.415, v_f1=0.98]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 06:34:24 [INFO] eps=3, lr=9e-06, t_loss=0.4916, v_loss=0.4153*, v_f1=0.9799*\n",
      "11/19 06:34:27 [INFO] ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in1k-fold_idx=0-epoch=03-val_loss=0.4153-val_score=0.9799.ckpt : saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:59<00:00,  1.66it/s]  1.03s/it, t_loss0=0.636, lr=1.02e-7, t_loss=0.492, v_loss=0.415, v_f1=0.98]\n",
      "Epoch 3: 100%|█████████▉| 791/792 [18:05<00:01,  1.03s/it, t_loss0=0.636, lr=8.37e-6, t_loss=0.49, v_loss=0.411, v_f1=0.98] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 06:38:55 [INFO] eps=3, lr=8.37e-06, t_loss=0.4899, v_loss=0.4106*, v_f1=0.9798 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 792/792 [18:05<00:00,  1.37s/it, t_loss0=0.636, lr=8.37e-6, t_loss=0.49, v_loss=0.411, v_f1=0.98]\n",
      "100%|██████████| 99/99 [00:59<00:00,  1.66it/s]  1.03s/it, t_loss0=0.378, lr=1.33e-7]\n",
      "Epoch 4:  25%|██▍       | 197/792 [04:23<10:13,  1.03s/it, t_loss0=0.378, lr=7.79e-6, t_loss=0.45, v_loss=0.415, v_f1=0.979]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 06:43:19 [INFO] eps=4, lr=7.79e-06, t_loss=0.4503, v_loss=0.4151 , v_f1=0.9790 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:59<00:00,  1.66it/s]  1.03s/it, t_loss0=0.352, lr=1.17e-7, t_loss=0.45, v_loss=0.415, v_f1=0.979]  \n",
      "Epoch 4:  50%|████▉     | 395/792 [08:47<06:47,  1.03s/it, t_loss0=0.352, lr=7.24e-6, t_loss=0.467, v_loss=0.412, v_f1=0.981]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 06:47:42 [INFO] eps=4, lr=7.24e-06, t_loss=0.4671, v_loss=0.4123 , v_f1=0.9808*\n",
      "11/19 06:47:45 [INFO] ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in1k-fold_idx=0-epoch=04-val_loss=0.4123-val_score=0.9808.ckpt : saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:59<00:00,  1.65it/s]  1.02s/it, t_loss0=0.5, lr=1.07e-7, t_loss=0.467, v_loss=0.412, v_f1=0.981]    \n",
      "Epoch 4:  75%|███████▍  | 593/792 [13:13<03:22,  1.02s/it, t_loss0=0.5, lr=6.73e-6, t_loss=0.462, v_loss=0.411, v_f1=0.98] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 06:52:09 [INFO] eps=4, lr=6.73e-06, t_loss=0.4616, v_loss=0.4113 , v_f1=0.9801 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:59<00:00,  1.65it/s]  1.01s/it, t_loss0=0.599, lr=1.02e-7, t_loss=0.462, v_loss=0.411, v_f1=0.98]\n",
      "Epoch 4: 100%|█████████▉| 791/792 [17:37<00:01,  1.01s/it, t_loss0=0.599, lr=6.26e-6, t_loss=0.46, v_loss=0.41, v_f1=0.981] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 06:56:33 [INFO] eps=4, lr=6.26e-06, t_loss=0.4596, v_loss=0.4098*, v_f1=0.9809*\n",
      "11/19 06:56:35 [INFO] ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in1k-fold_idx=0-epoch=04-val_loss=0.4098-val_score=0.9809.ckpt : saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 792/792 [17:40<00:00,  1.34s/it, t_loss0=0.599, lr=6.26e-6, t_loss=0.46, v_loss=0.41, v_f1=0.981]\n",
      "100%|██████████| 99/99 [00:59<00:00,  1.66it/s]  1.03s/it, t_loss0=0.811, lr=1.25e-7]\n",
      "Epoch 5:  25%|██▍       | 197/792 [04:24<10:11,  1.03s/it, t_loss0=0.811, lr=5.82e-6, t_loss=0.45, v_loss=0.412, v_f1=0.981]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 07:01:00 [INFO] eps=5, lr=5.82e-06, t_loss=0.4497, v_loss=0.4121 , v_f1=0.9810*\n",
      "11/19 07:01:02 [INFO] ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in1k-fold_idx=0-epoch=05-val_loss=0.4121-val_score=0.9810.ckpt : saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:59<00:00,  1.65it/s]  1.06s/it, t_loss0=0.607, lr=1.13e-7, t_loss=0.45, v_loss=0.412, v_f1=0.981]  \n",
      "Epoch 5:  50%|████▉     | 395/792 [08:51<07:00,  1.06s/it, t_loss0=0.607, lr=5.42e-6, t_loss=0.447, v_loss=0.415, v_f1=0.979]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 07:05:27 [INFO] eps=5, lr=5.42e-06, t_loss=0.4467, v_loss=0.4149 , v_f1=0.9792 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:59<00:00,  1.66it/s]  1.06s/it, t_loss0=0.38, lr=1.05e-7, t_loss=0.447, v_loss=0.415, v_f1=0.979]   \n",
      "Epoch 5:  75%|███████▍  | 593/792 [13:17<03:31,  1.06s/it, t_loss0=0.38, lr=5.04e-6, t_loss=0.442, v_loss=0.416, v_f1=0.979]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 07:09:53 [INFO] eps=5, lr=5.04e-06, t_loss=0.4423, v_loss=0.4159 , v_f1=0.9792 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:00<00:00,  1.65it/s]  1.03s/it, t_loss0=0.511, lr=1.01e-7, t_loss=0.442, v_loss=0.416, v_f1=0.979] \n",
      "Epoch 5: 100%|█████████▉| 791/792 [17:42<00:01,  1.03s/it, t_loss0=0.511, lr=4.68e-6, t_loss=0.446, v_loss=0.417, v_f1=0.98] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 07:14:18 [INFO] eps=5, lr=4.68e-06, t_loss=0.4456, v_loss=0.4171 , v_f1=0.9795 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 792/792 [17:42<00:00,  1.34s/it, t_loss0=0.511, lr=4.68e-6, t_loss=0.446, v_loss=0.417, v_f1=0.98]\n",
      "100%|██████████| 99/99 [01:00<00:00,  1.65it/s]  1.05s/it, t_loss0=0.353, lr=1.18e-7]\n",
      "Epoch 6:  25%|██▍       | 197/792 [04:25<10:25,  1.05s/it, t_loss0=0.353, lr=4.36e-6, t_loss=0.436, v_loss=0.418, v_f1=0.979]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 07:18:43 [INFO] eps=6, lr=4.36e-06, t_loss=0.4361, v_loss=0.4178 , v_f1=0.9785 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:59<00:00,  1.66it/s]  1.06s/it, t_loss0=0.44, lr=1.1e-7, t_loss=0.436, v_loss=0.418, v_f1=0.979]    \n",
      "Epoch 6:  50%|████▉     | 395/792 [08:50<06:58,  1.06s/it, t_loss0=0.44, lr=4.05e-6, t_loss=0.438, v_loss=0.413, v_f1=0.981]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 07:23:08 [INFO] eps=6, lr=4.05e-06, t_loss=0.4378, v_loss=0.4132 , v_f1=0.9809 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:00<00:00,  1.63it/s]  1.02s/it, t_loss0=0.347, lr=1.04e-7, t_loss=0.438, v_loss=0.413, v_f1=0.981] \n",
      "Epoch 6:  75%|███████▍  | 593/792 [13:17<03:23,  1.02s/it, t_loss0=0.347, lr=3.77e-6, t_loss=0.438, v_loss=0.419, v_f1=0.98] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 07:27:35 [INFO] eps=6, lr=3.77e-06, t_loss=0.4384, v_loss=0.4186 , v_f1=0.9804 \n",
      "11/19 07:27:35 [INFO] NO_MORE_TRAINING, best_score=0.9810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:00<00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 07:28:35 [INFO] EMA ::: ema_v_loss=0.4077, ema_v_f1=0.9827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 07:28:38 [INFO] ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in1k-fold_idx=0-epoch=06-val_loss=0.4077-val_score=0.9827-ema.ckpt : (ema) saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6:  75%|███████▍  | 593/792 [14:19<04:48,  1.45s/it, t_loss0=0.347, lr=3.77e-6, t_loss=0.438, v_loss=0.419, v_f1=0.98]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 07:28:38 [INFO] fold_idx=0 finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>ema_v_f1</td><td>▁</td></tr><tr><td>ema_v_loss</td><td>▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▁▂▂▂▄▄▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▇▇▇▇▇▇▇▇█████</td></tr><tr><td>lr</td><td>▇▅▆█▇▁▂▂▇▄▃▂▆▃▂▃▂▄▃▄▃▁▁▂▃▁▂▁▃▃▂▃▁▂▂▃▁▁▂▁</td></tr><tr><td>step</td><td>▁▁▂▃▃▁▁▂▂▃▃▄▄▅▅▆█▁▂▃▄▅▇██▃▄▅▂▄▄▅▅▆█▂▃▃▄▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>ema_v_f1</td><td>0.98265</td></tr><tr><td>ema_v_loss</td><td>0.40765</td></tr><tr><td>epoch</td><td>6</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>step</td><td>594</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /home/gooruem/Competition/BIRD/dacon2024_bird_lowres_image_classification/wandb/offline-run-20241119_054517-1tf3ajiq<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20241119_054517-1tf3ajiq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: can't open file '/home/gooruem/send_telegram.py': [Errno 2] No such file or directory\n",
      "11/19 07:28:41 [INFO] fold_idx=1 started\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 07:28:42 [INFO] load_img_size=336\n",
      "11/19 07:28:42 [INFO] load_img_size=336\n",
      "11/19 07:28:42 [INFO] create_model: timm/eva_large_patch14_336.in22k_ft_in22k_in1k\n",
      "11/19 07:28:42 [INFO] Loading pretrained weights from Hugging Face hub (timm/eva_large_patch14_336.in22k_ft_in22k_in1k)\n",
      "11/19 07:28:43 [INFO] [timm/eva_large_patch14_336.in22k_ft_in22k_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "11/19 07:28:45 [INFO] use_amp=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_181389/2507413745.py:14: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
      "100%|██████████| 99/99 [00:59<00:00,  1.65it/s]  1.03s/it, t_loss0=0.573, lr=1.8e-7] \n",
      "Epoch 1:  25%|██▍       | 197/792 [04:25<10:11,  1.03s/it, t_loss0=0.573, lr=1.86e-5, t_loss=1.11, v_loss=0.516, v_f1=0.958]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 07:33:10 [INFO] eps=1, lr=1.86e-05, t_loss=1.1110, v_loss=0.5160*, v_f1=0.9584*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:00<00:00,  1.65it/s]  1.02s/it, t_loss0=0.422, lr=1.42e-7, t_loss=1.11, v_loss=0.516, v_f1=0.958]  \n",
      "Epoch 1:  50%|████▉     | 395/792 [08:51<06:44,  1.02s/it, t_loss0=0.422, lr=1.73e-5, t_loss=0.871, v_loss=0.469, v_f1=0.966]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 07:37:37 [INFO] eps=1, lr=1.73e-05, t_loss=0.8705, v_loss=0.4685*, v_f1=0.9663*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:00<00:00,  1.64it/s]  1.02s/it, t_loss0=0.594, lr=1.17e-7, t_loss=0.871, v_loss=0.469, v_f1=0.966]  \n",
      "Epoch 1:  75%|███████▍  | 593/792 [13:18<03:23,  1.02s/it, t_loss0=0.594, lr=1.61e-5, t_loss=0.774, v_loss=0.455, v_f1=0.967]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 07:42:03 [INFO] eps=1, lr=1.61e-05, t_loss=0.7738, v_loss=0.4554*, v_f1=0.9667*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:00<00:00,  1.64it/s]  1.06s/it, t_loss0=0.874, lr=1.04e-7, t_loss=0.774, v_loss=0.455, v_f1=0.967]  \n",
      "Epoch 1: 100%|█████████▉| 791/792 [17:43<00:01,  1.06s/it, t_loss0=0.874, lr=1.5e-5, t_loss=0.725, v_loss=0.443, v_f1=0.969] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 07:46:28 [INFO] eps=1, lr=1.5e-05, t_loss=0.7250, v_loss=0.4430*, v_f1=0.9688*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 792/792 [17:43<00:00,  1.34s/it, t_loss0=0.874, lr=1.5e-5, t_loss=0.725, v_loss=0.443, v_f1=0.969]\n",
      "100%|██████████| 99/99 [01:00<00:00,  1.64it/s]  1.04s/it, t_loss0=0.37, lr=1.6e-7]  \n",
      "Epoch 2:  25%|██▍       | 197/792 [04:26<10:17,  1.04s/it, t_loss0=0.37, lr=1.39e-5, t_loss=0.528, v_loss=0.434, v_f1=0.971]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 07:50:54 [INFO] eps=2, lr=1.39e-05, t_loss=0.5282, v_loss=0.4341*, v_f1=0.9714*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:59<00:00,  1.66it/s]  1.05s/it, t_loss0=0.46, lr=1.31e-7, t_loss=0.528, v_loss=0.434, v_f1=0.971]   \n",
      "Epoch 2:  50%|████▉     | 395/792 [08:51<06:55,  1.05s/it, t_loss0=0.46, lr=1.29e-5, t_loss=0.519, v_loss=0.433, v_f1=0.973]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 07:55:19 [INFO] eps=2, lr=1.29e-05, t_loss=0.5186, v_loss=0.4330*, v_f1=0.9729*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:00<00:00,  1.64it/s]  1.05s/it, t_loss0=0.441, lr=1.13e-7, t_loss=0.519, v_loss=0.433, v_f1=0.973] \n",
      "Epoch 2:  75%|███████▍  | 593/792 [13:16<03:29,  1.05s/it, t_loss0=0.441, lr=1.2e-5, t_loss=0.519, v_loss=0.431, v_f1=0.974] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 07:59:45 [INFO] eps=2, lr=1.2e-05, t_loss=0.5188, v_loss=0.4308*, v_f1=0.9737*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:00<00:00,  1.63it/s]  1.02s/it, t_loss0=0.611, lr=1.03e-7, t_loss=0.519, v_loss=0.431, v_f1=0.974] \n",
      "Epoch 2: 100%|█████████▉| 791/792 [17:42<00:01,  1.02s/it, t_loss0=0.611, lr=1.12e-5, t_loss=0.517, v_loss=0.428, v_f1=0.975]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 08:04:10 [INFO] eps=2, lr=1.12e-05, t_loss=0.5167, v_loss=0.4275*, v_f1=0.9751*\n",
      "11/19 08:04:13 [INFO] ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in1k-fold_idx=1-epoch=02-val_loss=0.4275-val_score=0.9751.ckpt : saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 792/792 [17:44<00:00,  1.34s/it, t_loss0=0.611, lr=1.12e-5, t_loss=0.517, v_loss=0.428, v_f1=0.975]\n",
      "100%|██████████| 99/99 [01:00<00:00,  1.64it/s]  1.02s/it, t_loss0=0.377, lr=1.45e-7]\n",
      "Epoch 3:  25%|██▍       | 197/792 [04:25<10:07,  1.02s/it, t_loss0=0.377, lr=1.04e-5, t_loss=0.491, v_loss=0.421, v_f1=0.978]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 08:08:38 [INFO] eps=3, lr=1.04e-05, t_loss=0.4905, v_loss=0.4208*, v_f1=0.9778*\n",
      "11/19 08:08:41 [INFO] ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in1k-fold_idx=1-epoch=03-val_loss=0.4208-val_score=0.9778.ckpt : saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:00<00:00,  1.65it/s]  1.08s/it, t_loss0=0.478, lr=1.23e-7, t_loss=0.491, v_loss=0.421, v_f1=0.978]  \n",
      "Epoch 3:  50%|████▉     | 395/792 [08:55<07:10,  1.08s/it, t_loss0=0.478, lr=9.68e-6, t_loss=0.479, v_loss=0.427, v_f1=0.975]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 08:13:08 [INFO] eps=3, lr=9.68e-06, t_loss=0.4787, v_loss=0.4269 , v_f1=0.9754 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:00<00:00,  1.65it/s]  1.06s/it, t_loss0=0.484, lr=1.1e-7, t_loss=0.479, v_loss=0.427, v_f1=0.975]   \n",
      "Epoch 3:  75%|███████▍  | 593/792 [13:22<03:30,  1.06s/it, t_loss0=0.484, lr=9e-6, t_loss=0.478, v_loss=0.422, v_f1=0.978]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 08:17:36 [INFO] eps=3, lr=9e-06, t_loss=0.4778, v_loss=0.4217 , v_f1=0.9785*\n",
      "11/19 08:17:38 [INFO] ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in1k-fold_idx=1-epoch=03-val_loss=0.4217-val_score=0.9785.ckpt : saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:00<00:00,  1.64it/s]  1.04s/it, t_loss0=0.411, lr=1.02e-7, t_loss=0.478, v_loss=0.422, v_f1=0.978]\n",
      "Epoch 3: 100%|█████████▉| 791/792 [17:51<00:01,  1.04s/it, t_loss0=0.411, lr=8.37e-6, t_loss=0.48, v_loss=0.42, v_f1=0.977]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 08:22:04 [INFO] eps=3, lr=8.37e-06, t_loss=0.4801, v_loss=0.4201*, v_f1=0.9772 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 792/792 [17:51<00:00,  1.35s/it, t_loss0=0.411, lr=8.37e-6, t_loss=0.48, v_loss=0.42, v_f1=0.977]\n",
      "100%|██████████| 99/99 [01:00<00:00,  1.64it/s]  1.03s/it, t_loss0=0.57, lr=1.33e-7] \n",
      "Epoch 4:  25%|██▍       | 197/792 [04:25<10:15,  1.03s/it, t_loss0=0.57, lr=7.79e-6, t_loss=0.448, v_loss=0.419, v_f1=0.977]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 08:26:29 [INFO] eps=4, lr=7.79e-06, t_loss=0.4476, v_loss=0.4193*, v_f1=0.9768 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:00<00:00,  1.64it/s]  1.04s/it, t_loss0=0.339, lr=1.17e-7, t_loss=0.448, v_loss=0.419, v_f1=0.977]  \n",
      "Epoch 4:  50%|████▉     | 395/792 [08:50<06:51,  1.04s/it, t_loss0=0.339, lr=7.24e-6, t_loss=0.451, v_loss=0.423, v_f1=0.976]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 08:30:55 [INFO] eps=4, lr=7.24e-06, t_loss=0.4512, v_loss=0.4233 , v_f1=0.9761 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:59<00:00,  1.65it/s]  1.05s/it, t_loss0=0.353, lr=1.07e-7, t_loss=0.451, v_loss=0.423, v_f1=0.976]  \n",
      "Epoch 4:  75%|███████▍  | 593/792 [13:17<03:27,  1.05s/it, t_loss0=0.353, lr=6.73e-6, t_loss=0.45, v_loss=0.421, v_f1=0.975] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 08:35:22 [INFO] eps=4, lr=6.73e-06, t_loss=0.4504, v_loss=0.4208 , v_f1=0.9752 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:00<00:00,  1.64it/s]  1.03s/it, t_loss0=0.481, lr=1.02e-7, t_loss=0.45, v_loss=0.421, v_f1=0.975]  \n",
      "Epoch 4: 100%|█████████▉| 791/792 [17:47<00:01,  1.03s/it, t_loss0=0.481, lr=6.26e-6, t_loss=0.451, v_loss=0.428, v_f1=0.973]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 08:39:52 [INFO] eps=4, lr=6.26e-06, t_loss=0.4505, v_loss=0.4281 , v_f1=0.9733 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 792/792 [17:47<00:00,  1.35s/it, t_loss0=0.481, lr=6.26e-6, t_loss=0.451, v_loss=0.428, v_f1=0.973]\n",
      "100%|██████████| 99/99 [01:00<00:00,  1.63it/s]  1.05s/it, t_loss0=0.354, lr=1.25e-7]\n",
      "Epoch 5:  25%|██▍       | 197/792 [04:27<10:22,  1.05s/it, t_loss0=0.354, lr=5.82e-6, t_loss=0.453, v_loss=0.421, v_f1=0.979]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 08:44:20 [INFO] eps=5, lr=5.82e-06, t_loss=0.4531, v_loss=0.4211 , v_f1=0.9793*\n",
      "11/19 08:44:23 [INFO] ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in1k-fold_idx=1-epoch=05-val_loss=0.4211-val_score=0.9793.ckpt : saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:00<00:00,  1.63it/s]  1.04s/it, t_loss0=0.347, lr=1.13e-7, t_loss=0.453, v_loss=0.421, v_f1=0.979]  \n",
      "Epoch 5:  50%|████▉     | 395/792 [08:57<06:52,  1.04s/it, t_loss0=0.347, lr=5.42e-6, t_loss=0.446, v_loss=0.42, v_f1=0.977] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 08:48:50 [INFO] eps=5, lr=5.42e-06, t_loss=0.4458, v_loss=0.4197 , v_f1=0.9773 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:00<00:00,  1.63it/s]  1.01s/it, t_loss0=0.346, lr=1.05e-7, t_loss=0.446, v_loss=0.42, v_f1=0.977]  \n",
      "Epoch 5:  75%|███████▍  | 593/792 [13:24<03:21,  1.01s/it, t_loss0=0.346, lr=5.04e-6, t_loss=0.449, v_loss=0.422, v_f1=0.976]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 08:53:16 [INFO] eps=5, lr=5.04e-06, t_loss=0.4490, v_loss=0.4216 , v_f1=0.9765 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:00<00:00,  1.63it/s]  1.03s/it, t_loss0=0.352, lr=1.01e-7, t_loss=0.449, v_loss=0.422, v_f1=0.976]  \n",
      "Epoch 5: 100%|█████████▉| 791/792 [17:51<00:01,  1.03s/it, t_loss0=0.352, lr=4.68e-6, t_loss=0.449, v_loss=0.418, v_f1=0.976]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 08:57:44 [INFO] eps=5, lr=4.68e-06, t_loss=0.4486, v_loss=0.4182*, v_f1=0.9757 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 792/792 [17:51<00:00,  1.35s/it, t_loss0=0.352, lr=4.68e-6, t_loss=0.449, v_loss=0.418, v_f1=0.976]\n",
      "100%|██████████| 99/99 [01:01<00:00,  1.62it/s]  1.06s/it, t_loss0=0.36, lr=1.18e-7] \n",
      "Epoch 6:  25%|██▍       | 197/792 [04:37<10:32,  1.06s/it, t_loss0=0.36, lr=4.36e-6, t_loss=0.436, v_loss=0.414, v_f1=0.979]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 09:02:21 [INFO] eps=6, lr=4.36e-06, t_loss=0.4358, v_loss=0.4141*, v_f1=0.9786 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:00<00:00,  1.64it/s]  1.02s/it, t_loss0=0.53, lr=1.1e-7, t_loss=0.436, v_loss=0.414, v_f1=0.979]    \n",
      "Epoch 6:  50%|████▉     | 395/792 [09:05<06:43,  1.02s/it, t_loss0=0.53, lr=4.05e-6, t_loss=0.438, v_loss=0.421, v_f1=0.977]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 09:06:49 [INFO] eps=6, lr=4.05e-06, t_loss=0.4380, v_loss=0.4206 , v_f1=0.9768 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:01<00:00,  1.62it/s]  1.10s/it, t_loss0=0.351, lr=1.04e-7, t_loss=0.438, v_loss=0.421, v_f1=0.977] \n",
      "Epoch 6:  75%|███████▍  | 593/792 [13:33<03:39,  1.10s/it, t_loss0=0.351, lr=3.77e-6, t_loss=0.441, v_loss=0.414, v_f1=0.978]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 09:11:18 [INFO] eps=6, lr=3.77e-06, t_loss=0.4413, v_loss=0.4136*, v_f1=0.9784 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:00<00:00,  1.62it/s]  1.09s/it, t_loss0=0.351, lr=1.01e-7, t_loss=0.441, v_loss=0.414, v_f1=0.978]  \n",
      "Epoch 6: 100%|█████████▉| 791/792 [18:02<00:01,  1.09s/it, t_loss0=0.351, lr=3.5e-6, t_loss=0.439, v_loss=0.418, v_f1=0.976] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 09:15:47 [INFO] eps=6, lr=3.5e-06, t_loss=0.4392, v_loss=0.4180 , v_f1=0.9764 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 792/792 [18:02<00:00,  1.37s/it, t_loss0=0.351, lr=3.5e-6, t_loss=0.439, v_loss=0.418, v_f1=0.976]\n",
      "100%|██████████| 99/99 [01:01<00:00,  1.62it/s]  1.06s/it, t_loss0=0.34, lr=1.14e-7] \n",
      "Epoch 7:  25%|██▍       | 197/792 [04:28<10:28,  1.06s/it, t_loss0=0.34, lr=3.26e-6, t_loss=0.433, v_loss=0.409, v_f1=0.981]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 09:20:15 [INFO] eps=7, lr=3.26e-06, t_loss=0.4330, v_loss=0.4095*, v_f1=0.9810*\n",
      "11/19 09:20:18 [INFO] ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in1k-fold_idx=1-epoch=07-val_loss=0.4095-val_score=0.9810.ckpt : saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:01<00:00,  1.62it/s]  1.07s/it, t_loss0=0.35, lr=1.07e-7, t_loss=0.433, v_loss=0.409, v_f1=0.981]   \n",
      "Epoch 7:  50%|████▉     | 395/792 [08:59<07:03,  1.07s/it, t_loss0=0.35, lr=3.03e-6, t_loss=0.434, v_loss=0.413, v_f1=0.979]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 09:24:46 [INFO] eps=7, lr=3.03e-06, t_loss=0.4344, v_loss=0.4126 , v_f1=0.9791 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:00<00:00,  1.62it/s]  1.09s/it, t_loss0=0.796, lr=1.03e-7, t_loss=0.434, v_loss=0.413, v_f1=0.979] \n",
      "Epoch 7:  75%|███████▍  | 593/792 [13:27<03:35,  1.09s/it, t_loss0=0.796, lr=2.82e-6, t_loss=0.433, v_loss=0.415, v_f1=0.98] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 09:29:14 [INFO] eps=7, lr=2.82e-06, t_loss=0.4327, v_loss=0.4154 , v_f1=0.9804 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:01<00:00,  1.61it/s]  1.06s/it, t_loss0=0.355, lr=1.01e-7, t_loss=0.433, v_loss=0.415, v_f1=0.98]  \n",
      "Epoch 7: 100%|█████████▉| 791/792 [17:56<00:01,  1.06s/it, t_loss0=0.355, lr=2.62e-6, t_loss=0.436, v_loss=0.416, v_f1=0.978]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 09:33:43 [INFO] eps=7, lr=2.62e-06, t_loss=0.4361, v_loss=0.4163 , v_f1=0.9778 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 792/792 [17:56<00:00,  1.36s/it, t_loss0=0.355, lr=2.62e-6, t_loss=0.436, v_loss=0.416, v_f1=0.978]\n",
      "100%|██████████| 99/99 [01:01<00:00,  1.62it/s]  1.04s/it, t_loss0=0.459, lr=1.1e-7] \n",
      "Epoch 8:  25%|██▍       | 197/792 [04:28<10:19,  1.04s/it, t_loss0=0.459, lr=2.44e-6, t_loss=0.426, v_loss=0.415, v_f1=0.981]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 09:38:11 [INFO] eps=8, lr=2.44e-06, t_loss=0.4257, v_loss=0.4150 , v_f1=0.9810 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:01<00:00,  1.62it/s]  1.05s/it, t_loss0=0.35, lr=1.05e-7, t_loss=0.426, v_loss=0.415, v_f1=0.981]   \n",
      "Epoch 8:  50%|████▉     | 395/792 [08:58<06:58,  1.05s/it, t_loss0=0.35, lr=2.27e-6, t_loss=0.434, v_loss=0.416, v_f1=0.978]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 09:42:42 [INFO] eps=8, lr=2.27e-06, t_loss=0.4336, v_loss=0.4165 , v_f1=0.9781 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:00<00:00,  1.63it/s]  1.06s/it, t_loss0=0.425, lr=1.02e-7, t_loss=0.434, v_loss=0.416, v_f1=0.978] \n",
      "Epoch 8:  75%|███████▍  | 593/792 [13:26<03:31,  1.06s/it, t_loss0=0.425, lr=2.11e-6, t_loss=0.436, v_loss=0.418, v_f1=0.98] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 09:47:09 [INFO] eps=8, lr=2.11e-06, t_loss=0.4361, v_loss=0.4177 , v_f1=0.9797 \n",
      "11/19 09:47:09 [INFO] NO_MORE_TRAINING, best_score=0.9810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:01<00:00,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 09:48:10 [INFO] EMA ::: ema_v_loss=0.4117, ema_v_f1=0.9806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 09:48:13 [INFO] ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in1k-fold_idx=1-epoch=08-val_loss=0.4117-val_score=0.9806-ema.ckpt : (ema) saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8:  75%|███████▍  | 593/792 [14:30<04:52,  1.47s/it, t_loss0=0.425, lr=2.11e-6, t_loss=0.436, v_loss=0.418, v_f1=0.98]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 09:48:14 [INFO] fold_idx=1 finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>ema_v_f1</td><td>▁</td></tr><tr><td>ema_v_loss</td><td>▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▇▇▇████</td></tr><tr><td>lr</td><td>▇█▂▄▂▅▄▄▆▅▄▃▄▁▄▃▁▃▂▂▂▁▁▃▁▁▁▃▂▂▁▁▂▂▂▂▁▂▂▁</td></tr><tr><td>step</td><td>▂▃▄▅▅▅▆▃█▂▅▅▆▆▇▅▇▂▆▇▁▂▂▃▄▄▅▆▇█▂▃▄▅▆▁▂▃▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>ema_v_f1</td><td>0.98064</td></tr><tr><td>ema_v_loss</td><td>0.41173</td></tr><tr><td>epoch</td><td>8</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>step</td><td>594</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /home/gooruem/Competition/BIRD/dacon2024_bird_lowres_image_classification/wandb/offline-run-20241119_072841-vhv4v7ch<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20241119_072841-vhv4v7ch/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: can't open file '/home/gooruem/send_telegram.py': [Errno 2] No such file or directory\n",
      "11/19 09:48:17 [INFO] fold_idx=2 started\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 09:48:17 [INFO] load_img_size=336\n",
      "11/19 09:48:17 [INFO] load_img_size=336\n",
      "11/19 09:48:17 [INFO] create_model: timm/eva_large_patch14_336.in22k_ft_in22k_in1k\n",
      "11/19 09:48:18 [INFO] Loading pretrained weights from Hugging Face hub (timm/eva_large_patch14_336.in22k_ft_in22k_in1k)\n",
      "11/19 09:48:18 [INFO] [timm/eva_large_patch14_336.in22k_ft_in22k_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "11/19 09:48:19 [INFO] use_amp=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_181389/2507413745.py:14: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
      "100%|██████████| 99/99 [01:01<00:00,  1.62it/s]  1.09s/it, t_loss0=0.744, lr=1.8e-7] \n",
      "Epoch 1:  25%|██▍       | 197/792 [04:29<10:48,  1.09s/it, t_loss0=0.744, lr=1.86e-5, t_loss=1.2, v_loss=0.513, v_f1=0.959]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 09:52:49 [INFO] eps=1, lr=1.86e-05, t_loss=1.2029, v_loss=0.5129*, v_f1=0.9589*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:01<00:00,  1.60it/s]  1.04s/it, t_loss0=0.652, lr=1.42e-7, t_loss=1.2, v_loss=0.513, v_f1=0.959]  \n",
      "Epoch 1:  50%|████▉     | 395/792 [08:58<06:54,  1.04s/it, t_loss0=0.652, lr=1.73e-5, t_loss=0.905, v_loss=0.466, v_f1=0.966]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 09:57:18 [INFO] eps=1, lr=1.73e-05, t_loss=0.9054, v_loss=0.4656*, v_f1=0.9663*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:01<00:00,  1.60it/s]  1.02s/it, t_loss0=0.358, lr=1.17e-7, t_loss=0.905, v_loss=0.466, v_f1=0.966]  \n",
      "Epoch 1:  75%|███████▍  | 593/792 [13:30<03:22,  1.02s/it, t_loss0=0.358, lr=1.61e-5, t_loss=0.802, v_loss=0.453, v_f1=0.969]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 10:01:50 [INFO] eps=1, lr=1.61e-05, t_loss=0.8018, v_loss=0.4533*, v_f1=0.9687*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:01<00:00,  1.62it/s]  1.05s/it, t_loss0=0.477, lr=1.04e-7, t_loss=0.802, v_loss=0.453, v_f1=0.969]  \n",
      "Epoch 1: 100%|█████████▉| 791/792 [18:00<00:01,  1.05s/it, t_loss0=0.477, lr=1.5e-5, t_loss=0.745, v_loss=0.442, v_f1=0.97]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 10:06:20 [INFO] eps=1, lr=1.5e-05, t_loss=0.7450, v_loss=0.4425*, v_f1=0.9703*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 792/792 [18:00<00:00,  1.36s/it, t_loss0=0.477, lr=1.5e-5, t_loss=0.745, v_loss=0.442, v_f1=0.97]\n",
      "100%|██████████| 99/99 [01:01<00:00,  1.62it/s]  1.04s/it, t_loss0=0.722, lr=1.6e-7] \n",
      "Epoch 2:  25%|██▍       | 197/792 [04:29<10:16,  1.04s/it, t_loss0=0.722, lr=1.39e-5, t_loss=0.525, v_loss=0.433, v_f1=0.972]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 10:10:50 [INFO] eps=2, lr=1.39e-05, t_loss=0.5246, v_loss=0.4332*, v_f1=0.9716*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:01<00:00,  1.61it/s]  1.09s/it, t_loss0=0.481, lr=1.31e-7, t_loss=0.525, v_loss=0.433, v_f1=0.972]  \n",
      "Epoch 2:  50%|████▉     | 395/792 [08:59<07:12,  1.09s/it, t_loss0=0.481, lr=1.29e-5, t_loss=0.523, v_loss=0.431, v_f1=0.973]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 10:15:20 [INFO] eps=2, lr=1.29e-05, t_loss=0.5229, v_loss=0.4311*, v_f1=0.9729*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:02<00:00,  1.59it/s]  1.08s/it, t_loss0=0.394, lr=1.13e-7, t_loss=0.523, v_loss=0.431, v_f1=0.973]  \n",
      "Epoch 2:  75%|███████▍  | 593/792 [13:31<03:34,  1.08s/it, t_loss0=0.394, lr=1.2e-5, t_loss=0.525, v_loss=0.433, v_f1=0.973] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 10:19:51 [INFO] eps=2, lr=1.2e-05, t_loss=0.5247, v_loss=0.4333 , v_f1=0.9731*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:01<00:00,  1.62it/s]  1.07s/it, t_loss0=0.397, lr=1.03e-7, t_loss=0.525, v_loss=0.433, v_f1=0.973] \n",
      "Epoch 2: 100%|█████████▉| 791/792 [18:00<00:01,  1.07s/it, t_loss0=0.397, lr=1.12e-5, t_loss=0.521, v_loss=0.427, v_f1=0.973]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 10:24:20 [INFO] eps=2, lr=1.12e-05, t_loss=0.5206, v_loss=0.4269*, v_f1=0.9734*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 792/792 [18:00<00:00,  1.36s/it, t_loss0=0.397, lr=1.12e-5, t_loss=0.521, v_loss=0.427, v_f1=0.973]\n",
      "100%|██████████| 99/99 [01:01<00:00,  1.61it/s]  1.05s/it, t_loss0=0.357, lr=1.45e-7]\n",
      "Epoch 3:  25%|██▍       | 197/792 [04:30<10:23,  1.05s/it, t_loss0=0.357, lr=1.04e-5, t_loss=0.494, v_loss=0.424, v_f1=0.976]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 10:28:51 [INFO] eps=3, lr=1.04e-05, t_loss=0.4945, v_loss=0.4236*, v_f1=0.9756*\n",
      "11/19 10:28:54 [INFO] ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in1k-fold_idx=2-epoch=03-val_loss=0.4236-val_score=0.9756.ckpt : saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:01<00:00,  1.60it/s]  1.08s/it, t_loss0=0.456, lr=1.23e-7, t_loss=0.494, v_loss=0.424, v_f1=0.976]  \n",
      "Epoch 3:  50%|████▉     | 395/792 [09:04<07:07,  1.08s/it, t_loss0=0.456, lr=9.68e-6, t_loss=0.488, v_loss=0.422, v_f1=0.978]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 10:33:25 [INFO] eps=3, lr=9.68e-06, t_loss=0.4884, v_loss=0.4217*, v_f1=0.9779*\n",
      "11/19 10:33:27 [INFO] ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in1k-fold_idx=2-epoch=03-val_loss=0.4217-val_score=0.9779.ckpt : saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:08<00:00,  1.44it/s]  1.11s/it, t_loss0=0.488, lr=1.1e-7, t_loss=0.488, v_loss=0.422, v_f1=0.978]   \n",
      "Epoch 3:  75%|███████▍  | 593/792 [13:57<03:40,  1.11s/it, t_loss0=0.488, lr=9e-6, t_loss=0.486, v_loss=0.422, v_f1=0.976]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 10:38:18 [INFO] eps=3, lr=9e-06, t_loss=0.4863, v_loss=0.4222 , v_f1=0.9760 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:01<00:00,  1.61it/s]  1.14s/it, t_loss0=0.348, lr=1.02e-7, t_loss=0.486, v_loss=0.422, v_f1=0.976]\n",
      "Epoch 3: 100%|█████████▉| 791/792 [18:38<00:01,  1.14s/it, t_loss0=0.348, lr=8.37e-6, t_loss=0.483, v_loss=0.421, v_f1=0.975]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 10:42:59 [INFO] eps=3, lr=8.37e-06, t_loss=0.4832, v_loss=0.4211*, v_f1=0.9754 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 792/792 [18:38<00:00,  1.41s/it, t_loss0=0.348, lr=8.37e-6, t_loss=0.483, v_loss=0.421, v_f1=0.975]\n",
      "100%|██████████| 99/99 [01:01<00:00,  1.61it/s]  1.09s/it, t_loss0=0.363, lr=1.33e-7]\n",
      "Epoch 4:  25%|██▍       | 197/792 [04:36<10:47,  1.09s/it, t_loss0=0.363, lr=7.79e-6, t_loss=0.464, v_loss=0.424, v_f1=0.974]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 10:47:35 [INFO] eps=4, lr=7.79e-06, t_loss=0.4638, v_loss=0.4238 , v_f1=0.9735 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:03<00:00,  1.57it/s]  1.08s/it, t_loss0=0.354, lr=1.17e-7, t_loss=0.464, v_loss=0.424, v_f1=0.974]  \n",
      "Epoch 4:  50%|████▉     | 395/792 [09:16<07:09,  1.08s/it, t_loss0=0.354, lr=7.24e-6, t_loss=0.455, v_loss=0.417, v_f1=0.978]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 10:52:15 [INFO] eps=4, lr=7.24e-06, t_loss=0.4550, v_loss=0.4174*, v_f1=0.9780*\n",
      "11/19 10:52:18 [INFO] ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in1k-fold_idx=2-epoch=04-val_loss=0.4174-val_score=0.9780.ckpt : saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:03<00:00,  1.56it/s]  1.10s/it, t_loss0=0.353, lr=1.07e-7, t_loss=0.455, v_loss=0.417, v_f1=0.978]  \n",
      "Epoch 4:  75%|███████▍  | 593/792 [14:02<03:38,  1.10s/it, t_loss0=0.353, lr=6.73e-6, t_loss=0.458, v_loss=0.417, v_f1=0.977]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 10:57:01 [INFO] eps=4, lr=6.73e-06, t_loss=0.4578, v_loss=0.4168*, v_f1=0.9771 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:01<00:00,  1.60it/s]  1.08s/it, t_loss0=0.838, lr=1.02e-7, t_loss=0.458, v_loss=0.417, v_f1=0.977]  \n",
      "Epoch 4: 100%|█████████▉| 791/792 [18:39<00:01,  1.08s/it, t_loss0=0.838, lr=6.26e-6, t_loss=0.458, v_loss=0.414, v_f1=0.98] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 11:01:39 [INFO] eps=4, lr=6.26e-06, t_loss=0.4583, v_loss=0.4143*, v_f1=0.9800*\n",
      "11/19 11:01:41 [INFO] ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in1k-fold_idx=2-epoch=04-val_loss=0.4143-val_score=0.9800.ckpt : saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 792/792 [18:42<00:00,  1.42s/it, t_loss0=0.838, lr=6.26e-6, t_loss=0.458, v_loss=0.414, v_f1=0.98]\n",
      "100%|██████████| 99/99 [01:01<00:00,  1.60it/s]  1.06s/it, t_loss0=0.353, lr=1.25e-7]\n",
      "Epoch 5:  25%|██▍       | 197/792 [04:35<10:33,  1.06s/it, t_loss0=0.353, lr=5.82e-6, t_loss=0.443, v_loss=0.42, v_f1=0.976]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 11:06:16 [INFO] eps=5, lr=5.82e-06, t_loss=0.4431, v_loss=0.4197 , v_f1=0.9760 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:01<00:00,  1.61it/s]  1.09s/it, t_loss0=0.35, lr=1.13e-7, t_loss=0.443, v_loss=0.42, v_f1=0.976]   \n",
      "Epoch 5:  50%|████▉     | 395/792 [09:08<07:14,  1.09s/it, t_loss0=0.35, lr=5.42e-6, t_loss=0.447, v_loss=0.418, v_f1=0.978]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 11:10:50 [INFO] eps=5, lr=5.42e-06, t_loss=0.4469, v_loss=0.4177 , v_f1=0.9781 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:03<00:00,  1.56it/s]  1.06s/it, t_loss0=0.356, lr=1.05e-7, t_loss=0.447, v_loss=0.418, v_f1=0.978] \n",
      "Epoch 5:  75%|███████▍  | 593/792 [13:43<03:30,  1.06s/it, t_loss0=0.356, lr=5.04e-6, t_loss=0.445, v_loss=0.419, v_f1=0.978]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 11:15:25 [INFO] eps=5, lr=5.04e-06, t_loss=0.4448, v_loss=0.4188 , v_f1=0.9780 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:01<00:00,  1.60it/s]  1.11s/it, t_loss0=0.638, lr=1.01e-7, t_loss=0.445, v_loss=0.419, v_f1=0.978]  \n",
      "Epoch 5: 100%|█████████▉| 791/792 [18:19<00:01,  1.11s/it, t_loss0=0.638, lr=4.68e-6, t_loss=0.446, v_loss=0.424, v_f1=0.977]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 11:20:01 [INFO] eps=5, lr=4.68e-06, t_loss=0.4457, v_loss=0.4240 , v_f1=0.9768 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 792/792 [18:19<00:00,  1.39s/it, t_loss0=0.638, lr=4.68e-6, t_loss=0.446, v_loss=0.424, v_f1=0.977]\n",
      "100%|██████████| 99/99 [01:01<00:00,  1.60it/s]  1.07s/it, t_loss0=0.341, lr=1.18e-7]\n",
      "Epoch 6:  25%|██▍       | 197/792 [04:31<10:35,  1.07s/it, t_loss0=0.341, lr=4.36e-6, t_loss=0.435, v_loss=0.418, v_f1=0.978]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 11:24:33 [INFO] eps=6, lr=4.36e-06, t_loss=0.4350, v_loss=0.4183 , v_f1=0.9783 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:01<00:00,  1.60it/s]  1.05s/it, t_loss0=0.343, lr=1.1e-7, t_loss=0.435, v_loss=0.418, v_f1=0.978]   \n",
      "Epoch 6:  50%|████▉     | 395/792 [09:02<06:55,  1.05s/it, t_loss0=0.343, lr=4.05e-6, t_loss=0.433, v_loss=0.42, v_f1=0.977]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 11:29:04 [INFO] eps=6, lr=4.05e-06, t_loss=0.4330, v_loss=0.4203 , v_f1=0.9772 \n",
      "11/19 11:29:04 [INFO] NO_MORE_TRAINING, best_score=0.9800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:02<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 11:30:06 [INFO] EMA ::: ema_v_loss=0.4149, ema_v_f1=0.9780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 11:30:09 [INFO] ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in1k-fold_idx=2-epoch=06-val_loss=0.4149-val_score=0.9780-ema.ckpt : (ema) saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6:  50%|████▉     | 395/792 [10:07<10:10,  1.54s/it, t_loss0=0.343, lr=4.05e-6, t_loss=0.433, v_loss=0.42, v_f1=0.977]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 11:30:09 [INFO] fold_idx=2 finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>ema_v_f1</td><td>▁</td></tr><tr><td>ema_v_loss</td><td>▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▂▂▂▂▄▄▄▄▄▄▅▅▅▅▅▇▇▇▇▇▇▇▇▇▇█████</td></tr><tr><td>lr</td><td>█▁▇▁▆▂▂▆▁▁▅▄▁▄▄▁▁▁▄▁▄▂▄▄▂▃▂▂▃▃▂▃▂▁▃▁▃▃▃▂</td></tr><tr><td>step</td><td>▁▂▂▄▄▆▆▇▄▆▇▇█▃▄▄▄▄▄▆▆▆▇██▃▃▄▆▂▂▄▄▅▅█▂▂▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>ema_v_f1</td><td>0.97796</td></tr><tr><td>ema_v_loss</td><td>0.41488</td></tr><tr><td>epoch</td><td>6</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>step</td><td>396</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /home/gooruem/Competition/BIRD/dacon2024_bird_lowres_image_classification/wandb/offline-run-20241119_094817-dtq9cdbf<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20241119_094817-dtq9cdbf/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: can't open file '/home/gooruem/send_telegram.py': [Errno 2] No such file or directory\n",
      "11/19 11:30:13 [INFO] fold_idx=3 started\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 11:30:14 [INFO] load_img_size=336\n",
      "11/19 11:30:14 [INFO] load_img_size=336\n",
      "11/19 11:30:14 [INFO] create_model: timm/eva_large_patch14_336.in22k_ft_in22k_in1k\n",
      "11/19 11:30:14 [INFO] Loading pretrained weights from Hugging Face hub (timm/eva_large_patch14_336.in22k_ft_in22k_in1k)\n",
      "11/19 11:30:14 [INFO] [timm/eva_large_patch14_336.in22k_ft_in22k_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "11/19 11:30:16 [INFO] use_amp=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_181389/2507413745.py:14: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
      "100%|██████████| 99/99 [01:02<00:00,  1.59it/s]  1.06s/it, t_loss0=0.958, lr=1.8e-7] \n",
      "Epoch 1:  25%|██▍       | 197/792 [04:31<10:31,  1.06s/it, t_loss0=0.958, lr=1.86e-5, t_loss=1.1, v_loss=0.489, v_f1=0.966]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 11:34:48 [INFO] eps=1, lr=1.86e-05, t_loss=1.1033, v_loss=0.4891*, v_f1=0.9660*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:01<00:00,  1.61it/s]  1.06s/it, t_loss0=0.494, lr=1.42e-7, t_loss=1.1, v_loss=0.489, v_f1=0.966]  \n",
      "Epoch 1:  50%|████▉     | 395/792 [09:02<06:59,  1.06s/it, t_loss0=0.494, lr=1.73e-5, t_loss=0.866, v_loss=0.448, v_f1=0.973]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 11:39:19 [INFO] eps=1, lr=1.73e-05, t_loss=0.8662, v_loss=0.4485*, v_f1=0.9725*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:02<00:00,  1.58it/s]  1.10s/it, t_loss0=0.744, lr=1.17e-7, t_loss=0.866, v_loss=0.448, v_f1=0.973]  \n",
      "Epoch 1:  75%|███████▍  | 593/792 [13:36<03:39,  1.10s/it, t_loss0=0.744, lr=1.61e-5, t_loss=0.78, v_loss=0.441, v_f1=0.973] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 11:43:52 [INFO] eps=1, lr=1.61e-05, t_loss=0.7804, v_loss=0.4412*, v_f1=0.9730*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:02<00:00,  1.59it/s]  1.04s/it, t_loss0=0.629, lr=1.04e-7, t_loss=0.78, v_loss=0.441, v_f1=0.973]  \n",
      "Epoch 1: 100%|█████████▉| 791/792 [18:08<00:01,  1.04s/it, t_loss0=0.629, lr=1.5e-5, t_loss=0.73, v_loss=0.439, v_f1=0.971] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 11:48:25 [INFO] eps=1, lr=1.5e-05, t_loss=0.7305, v_loss=0.4391*, v_f1=0.9712 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 792/792 [18:08<00:00,  1.37s/it, t_loss0=0.629, lr=1.5e-5, t_loss=0.73, v_loss=0.439, v_f1=0.971]\n",
      "100%|██████████| 99/99 [01:01<00:00,  1.60it/s]  1.08s/it, t_loss0=0.412, lr=1.6e-7] \n",
      "Epoch 2:  25%|██▍       | 197/792 [04:32<10:43,  1.08s/it, t_loss0=0.412, lr=1.39e-5, t_loss=0.533, v_loss=0.425, v_f1=0.977]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 11:52:57 [INFO] eps=2, lr=1.39e-05, t_loss=0.5326, v_loss=0.4249*, v_f1=0.9769*\n",
      "11/19 11:53:00 [INFO] ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in1k-fold_idx=3-epoch=02-val_loss=0.4249-val_score=0.9769.ckpt : saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:04<00:00,  1.54it/s]  1.08s/it, t_loss0=0.389, lr=1.31e-7, t_loss=0.533, v_loss=0.425, v_f1=0.977]  \n",
      "Epoch 2:  50%|████▉     | 395/792 [09:11<07:08,  1.08s/it, t_loss0=0.389, lr=1.29e-5, t_loss=0.536, v_loss=0.425, v_f1=0.976]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 11:57:37 [INFO] eps=2, lr=1.29e-05, t_loss=0.5356, v_loss=0.4251 , v_f1=0.9760 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:01<00:00,  1.60it/s]  1.07s/it, t_loss0=0.372, lr=1.13e-7, t_loss=0.536, v_loss=0.425, v_f1=0.976]  \n",
      "Epoch 2:  75%|███████▍  | 593/792 [13:45<03:33,  1.07s/it, t_loss0=0.372, lr=1.2e-5, t_loss=0.531, v_loss=0.417, v_f1=0.978] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 12:02:11 [INFO] eps=2, lr=1.2e-05, t_loss=0.5310, v_loss=0.4173*, v_f1=0.9777*\n",
      "11/19 12:02:14 [INFO] ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in1k-fold_idx=3-epoch=02-val_loss=0.4173-val_score=0.9777.ckpt : saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:04<00:00,  1.53it/s]  1.10s/it, t_loss0=0.431, lr=1.03e-7, t_loss=0.531, v_loss=0.417, v_f1=0.978] \n",
      "Epoch 2: 100%|█████████▉| 791/792 [18:31<00:01,  1.10s/it, t_loss0=0.431, lr=1.12e-5, t_loss=0.527, v_loss=0.412, v_f1=0.979]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 12:06:57 [INFO] eps=2, lr=1.12e-05, t_loss=0.5267, v_loss=0.4120*, v_f1=0.9786*\n",
      "11/19 12:07:00 [INFO] ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in1k-fold_idx=3-epoch=02-val_loss=0.4120-val_score=0.9786.ckpt : saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 792/792 [18:35<00:00,  1.41s/it, t_loss0=0.431, lr=1.12e-5, t_loss=0.527, v_loss=0.412, v_f1=0.979]\n",
      "100%|██████████| 99/99 [01:02<00:00,  1.60it/s]  1.06s/it, t_loss0=0.357, lr=1.45e-7]\n",
      "Epoch 3:  25%|██▍       | 197/792 [04:40<10:31,  1.06s/it, t_loss0=0.357, lr=1.04e-5, t_loss=0.482, v_loss=0.412, v_f1=0.979]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 12:11:41 [INFO] eps=3, lr=1.04e-05, t_loss=0.4823, v_loss=0.4116*, v_f1=0.9794*\n",
      "11/19 12:11:43 [INFO] ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in1k-fold_idx=3-epoch=03-val_loss=0.4116-val_score=0.9794.ckpt : saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:02<00:00,  1.59it/s]  1.11s/it, t_loss0=0.351, lr=1.23e-7, t_loss=0.482, v_loss=0.412, v_f1=0.979]  \n",
      "Epoch 3:  50%|████▉     | 395/792 [09:24<07:19,  1.11s/it, t_loss0=0.351, lr=9.68e-6, t_loss=0.473, v_loss=0.412, v_f1=0.98] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 12:16:25 [INFO] eps=3, lr=9.68e-06, t_loss=0.4727, v_loss=0.4118 , v_f1=0.9802*\n",
      "11/19 12:16:27 [INFO] ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in1k-fold_idx=3-epoch=03-val_loss=0.4118-val_score=0.9802.ckpt : saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:02<00:00,  1.59it/s]  1.14s/it, t_loss0=0.5, lr=1.1e-7, t_loss=0.473, v_loss=0.412, v_f1=0.98]     \n",
      "Epoch 3:  75%|███████▍  | 593/792 [14:09<03:47,  1.14s/it, t_loss0=0.5, lr=9e-6, t_loss=0.481, v_loss=0.413, v_f1=0.978] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 12:21:10 [INFO] eps=3, lr=9e-06, t_loss=0.4814, v_loss=0.4130 , v_f1=0.9783 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:03<00:00,  1.57it/s]  1.09s/it, t_loss0=0.543, lr=1.02e-7, t_loss=0.481, v_loss=0.413, v_f1=0.978]\n",
      "Epoch 3: 100%|█████████▉| 791/792 [18:49<00:01,  1.09s/it, t_loss0=0.543, lr=8.37e-6, t_loss=0.485, v_loss=0.406, v_f1=0.982]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 12:25:50 [INFO] eps=3, lr=8.37e-06, t_loss=0.4855, v_loss=0.4062*, v_f1=0.9825*\n",
      "11/19 12:25:53 [INFO] ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in1k-fold_idx=3-epoch=03-val_loss=0.4062-val_score=0.9825.ckpt : saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 792/792 [18:52<00:00,  1.43s/it, t_loss0=0.543, lr=8.37e-6, t_loss=0.485, v_loss=0.406, v_f1=0.982]\n",
      "100%|██████████| 99/99 [01:03<00:00,  1.57it/s]  1.06s/it, t_loss0=0.674, lr=1.33e-7]\n",
      "Epoch 4:  25%|██▍       | 197/792 [04:36<10:30,  1.06s/it, t_loss0=0.674, lr=7.79e-6, t_loss=0.463, v_loss=0.412, v_f1=0.978]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 12:30:29 [INFO] eps=4, lr=7.79e-06, t_loss=0.4629, v_loss=0.4122 , v_f1=0.9785 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:02<00:00,  1.59it/s]  1.12s/it, t_loss0=0.386, lr=1.17e-7, t_loss=0.463, v_loss=0.412, v_f1=0.978]  \n",
      "Epoch 4:  50%|████▉     | 395/792 [09:11<07:25,  1.12s/it, t_loss0=0.386, lr=7.24e-6, t_loss=0.46, v_loss=0.413, v_f1=0.979] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 12:35:04 [INFO] eps=4, lr=7.24e-06, t_loss=0.4600, v_loss=0.4126 , v_f1=0.9791 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:03<00:00,  1.57it/s]  1.00s/it, t_loss0=0.358, lr=1.07e-7, t_loss=0.46, v_loss=0.413, v_f1=0.979]  \n",
      "Epoch 4:  75%|███████▍  | 593/792 [13:45<03:19,  1.00s/it, t_loss0=0.358, lr=6.73e-6, t_loss=0.465, v_loss=0.41, v_f1=0.981]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 12:39:39 [INFO] eps=4, lr=6.73e-06, t_loss=0.4651, v_loss=0.4099 , v_f1=0.9809 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:02<00:00,  1.59it/s]  1.06s/it, t_loss0=0.357, lr=1.02e-7, t_loss=0.465, v_loss=0.41, v_f1=0.981]  \n",
      "Epoch 4: 100%|█████████▉| 791/792 [18:19<00:01,  1.06s/it, t_loss0=0.357, lr=6.26e-6, t_loss=0.462, v_loss=0.409, v_f1=0.98]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 12:44:12 [INFO] eps=4, lr=6.26e-06, t_loss=0.4621, v_loss=0.4088 , v_f1=0.9802 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 792/792 [18:19<00:00,  1.39s/it, t_loss0=0.357, lr=6.26e-6, t_loss=0.462, v_loss=0.409, v_f1=0.98]\n",
      "100%|██████████| 99/99 [01:01<00:00,  1.60it/s]  1.08s/it, t_loss0=0.362, lr=1.25e-7]\n",
      "Epoch 5:  25%|██▍       | 197/792 [04:33<10:42,  1.08s/it, t_loss0=0.362, lr=5.82e-6, t_loss=0.427, v_loss=0.406, v_f1=0.981]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 12:48:45 [INFO] eps=5, lr=5.82e-06, t_loss=0.4267, v_loss=0.4063 , v_f1=0.9811 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:03<00:00,  1.57it/s]  1.10s/it, t_loss0=0.629, lr=1.13e-7, t_loss=0.427, v_loss=0.406, v_f1=0.981]  \n",
      "Epoch 5:  50%|████▉     | 395/792 [09:09<07:14,  1.10s/it, t_loss0=0.629, lr=5.42e-6, t_loss=0.45, v_loss=0.406, v_f1=0.981] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 12:53:22 [INFO] eps=5, lr=5.42e-06, t_loss=0.4501, v_loss=0.4059*, v_f1=0.9815 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:03<00:00,  1.56it/s]  1.10s/it, t_loss0=0.39, lr=1.05e-7, t_loss=0.45, v_loss=0.406, v_f1=0.981]   \n",
      "Epoch 5:  75%|███████▍  | 593/792 [13:47<03:37,  1.10s/it, t_loss0=0.39, lr=5.04e-6, t_loss=0.446, v_loss=0.411, v_f1=0.979]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 12:58:00 [INFO] eps=5, lr=5.04e-06, t_loss=0.4462, v_loss=0.4111 , v_f1=0.9789 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:03<00:00,  1.56it/s]  1.08s/it, t_loss0=0.609, lr=1.01e-7, t_loss=0.446, v_loss=0.411, v_f1=0.979] \n",
      "Epoch 5: 100%|█████████▉| 791/792 [18:23<00:01,  1.08s/it, t_loss0=0.609, lr=4.68e-6, t_loss=0.449, v_loss=0.413, v_f1=0.981]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 13:02:36 [INFO] eps=5, lr=4.68e-06, t_loss=0.4488, v_loss=0.4134 , v_f1=0.9805 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 792/792 [18:23<00:00,  1.39s/it, t_loss0=0.609, lr=4.68e-6, t_loss=0.449, v_loss=0.413, v_f1=0.981]\n",
      "100%|██████████| 99/99 [01:03<00:00,  1.56it/s]  1.10s/it, t_loss0=0.438, lr=1.18e-7]\n",
      "Epoch 6:  25%|██▍       | 197/792 [04:36<10:55,  1.10s/it, t_loss0=0.438, lr=4.36e-6, t_loss=0.445, v_loss=0.409, v_f1=0.981]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 13:07:12 [INFO] eps=6, lr=4.36e-06, t_loss=0.4452, v_loss=0.4087 , v_f1=0.9812 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:02<00:00,  1.57it/s]  1.13s/it, t_loss0=0.367, lr=1.1e-7, t_loss=0.445, v_loss=0.409, v_f1=0.981]   \n",
      "Epoch 6:  50%|████▉     | 395/792 [09:16<07:28,  1.13s/it, t_loss0=0.367, lr=4.05e-6, t_loss=0.436, v_loss=0.407, v_f1=0.982]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 13:11:52 [INFO] eps=6, lr=4.05e-06, t_loss=0.4360, v_loss=0.4075 , v_f1=0.9818 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:03<00:00,  1.57it/s]  1.12s/it, t_loss0=0.331, lr=1.04e-7, t_loss=0.436, v_loss=0.407, v_f1=0.982]  \n",
      "Epoch 6:  75%|███████▍  | 593/792 [13:53<03:42,  1.12s/it, t_loss0=0.331, lr=3.77e-6, t_loss=0.442, v_loss=0.406, v_f1=0.981]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 13:16:29 [INFO] eps=6, lr=3.77e-06, t_loss=0.4422, v_loss=0.4061 , v_f1=0.9809 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:03<00:00,  1.57it/s]  1.04s/it, t_loss0=0.353, lr=1.01e-7, t_loss=0.442, v_loss=0.406, v_f1=0.981]  \n",
      "Epoch 6: 100%|█████████▉| 791/792 [18:29<00:01,  1.04s/it, t_loss0=0.353, lr=3.5e-6, t_loss=0.442, v_loss=0.402, v_f1=0.982] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 13:21:05 [INFO] eps=6, lr=3.5e-06, t_loss=0.4423, v_loss=0.4021*, v_f1=0.9824 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 792/792 [18:29<00:00,  1.40s/it, t_loss0=0.353, lr=3.5e-6, t_loss=0.442, v_loss=0.402, v_f1=0.982]\n",
      "100%|██████████| 99/99 [01:02<00:00,  1.57it/s]  1.04s/it, t_loss0=0.356, lr=1.14e-7]\n",
      "Epoch 7:  25%|██▍       | 197/792 [04:35<10:18,  1.04s/it, t_loss0=0.356, lr=3.26e-6, t_loss=0.432, v_loss=0.405, v_f1=0.981]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 13:25:40 [INFO] eps=7, lr=3.26e-06, t_loss=0.4323, v_loss=0.4051 , v_f1=0.9812 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:03<00:00,  1.56it/s]  1.11s/it, t_loss0=0.355, lr=1.07e-7, t_loss=0.432, v_loss=0.405, v_f1=0.981]  \n",
      "Epoch 7:  50%|████▉     | 395/792 [09:12<07:20,  1.11s/it, t_loss0=0.355, lr=3.03e-6, t_loss=0.426, v_loss=0.407, v_f1=0.979]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 13:30:17 [INFO] eps=7, lr=3.03e-06, t_loss=0.4263, v_loss=0.4070 , v_f1=0.9793 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:02<00:00,  1.59it/s]  1.10s/it, t_loss0=0.353, lr=1.03e-7, t_loss=0.426, v_loss=0.407, v_f1=0.979]  \n",
      "Epoch 7:  75%|███████▍  | 593/792 [13:48<03:38,  1.10s/it, t_loss0=0.353, lr=2.82e-6, t_loss=0.422, v_loss=0.41, v_f1=0.981] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 13:34:53 [INFO] eps=7, lr=2.82e-06, t_loss=0.4224, v_loss=0.4097 , v_f1=0.9806 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:02<00:00,  1.57it/s]  1.08s/it, t_loss0=0.334, lr=1.01e-7, t_loss=0.422, v_loss=0.41, v_f1=0.981]  \n",
      "Epoch 7: 100%|█████████▉| 791/792 [18:24<00:01,  1.08s/it, t_loss0=0.334, lr=2.62e-6, t_loss=0.426, v_loss=0.408, v_f1=0.981]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 13:39:29 [INFO] eps=7, lr=2.62e-06, t_loss=0.4257, v_loss=0.4084 , v_f1=0.9806 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 792/792 [18:24<00:00,  1.39s/it, t_loss0=0.334, lr=2.62e-6, t_loss=0.426, v_loss=0.408, v_f1=0.981]\n",
      "100%|██████████| 99/99 [01:03<00:00,  1.56it/s]  1.05s/it, t_loss0=0.352, lr=1.1e-7] \n",
      "Epoch 8:  25%|██▍       | 197/792 [04:37<10:25,  1.05s/it, t_loss0=0.352, lr=2.44e-6, t_loss=0.431, v_loss=0.41, v_f1=0.982]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 13:44:06 [INFO] eps=8, lr=2.44e-06, t_loss=0.4310, v_loss=0.4100 , v_f1=0.9819 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:03<00:00,  1.56it/s]  1.07s/it, t_loss0=0.448, lr=1.05e-7, t_loss=0.431, v_loss=0.41, v_f1=0.982]  \n",
      "Epoch 8:  50%|████▉     | 395/792 [09:13<07:06,  1.07s/it, t_loss0=0.448, lr=2.27e-6, t_loss=0.428, v_loss=0.411, v_f1=0.981]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 13:48:43 [INFO] eps=8, lr=2.27e-06, t_loss=0.4282, v_loss=0.4111 , v_f1=0.9809 \n",
      "11/19 13:48:43 [INFO] NO_MORE_TRAINING, best_score=0.9825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:03<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 13:49:47 [INFO] EMA ::: ema_v_loss=0.4033, ema_v_f1=0.9818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 13:49:49 [INFO] ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in1k-fold_idx=3-epoch=08-val_loss=0.4033-val_score=0.9818-ema.ckpt : (ema) saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8:  50%|████▉     | 395/792 [10:20<10:23,  1.57s/it, t_loss0=0.448, lr=2.27e-6, t_loss=0.428, v_loss=0.411, v_f1=0.981]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 13:49:50 [INFO] fold_idx=3 finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>ema_v_f1</td><td>▁</td></tr><tr><td>ema_v_loss</td><td>▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇█████</td></tr><tr><td>lr</td><td>█▂█▇▄▁▇▆▅▁▂▅▁▃▂▁▄▄▃▃▁▂▃▁▁▃▁▂▂▁▂▁▁▂▁▁▂▂▁▂</td></tr><tr><td>step</td><td>▂▄▄▇█▃▃▄▅▆▃▅▆▇█▄▄▆▆▇▃▄▄▄▅█▃▃▆▇▂▂▄▇▇██▁▁▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>ema_v_f1</td><td>0.98181</td></tr><tr><td>ema_v_loss</td><td>0.40329</td></tr><tr><td>epoch</td><td>8</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>step</td><td>396</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /home/gooruem/Competition/BIRD/dacon2024_bird_lowres_image_classification/wandb/offline-run-20241119_113013-97pqglst<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20241119_113013-97pqglst/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: can't open file '/home/gooruem/send_telegram.py': [Errno 2] No such file or directory\n",
      "11/19 13:49:53 [INFO] fold_idx=4 started\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 13:49:53 [INFO] load_img_size=336\n",
      "11/19 13:49:53 [INFO] load_img_size=336\n",
      "11/19 13:49:53 [INFO] create_model: timm/eva_large_patch14_336.in22k_ft_in22k_in1k\n",
      "11/19 13:49:53 [INFO] Loading pretrained weights from Hugging Face hub (timm/eva_large_patch14_336.in22k_ft_in22k_in1k)\n",
      "11/19 13:49:54 [INFO] [timm/eva_large_patch14_336.in22k_ft_in22k_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "11/19 13:49:56 [INFO] use_amp=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_181389/2507413745.py:14: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
      "100%|██████████| 99/99 [01:05<00:00,  1.52it/s]  1.11s/it, t_loss0=0.716, lr=1.8e-7] \n",
      "Epoch 1:  25%|██▍       | 197/792 [04:45<11:00,  1.11s/it, t_loss0=0.716, lr=1.86e-5, t_loss=1.15, v_loss=0.491, v_f1=0.964]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 13:54:41 [INFO] eps=1, lr=1.86e-05, t_loss=1.1469, v_loss=0.4905*, v_f1=0.9641*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:03<00:00,  1.56it/s]  1.06s/it, t_loss0=0.489, lr=1.42e-7, t_loss=1.15, v_loss=0.491, v_f1=0.964]  \n",
      "Epoch 1:  50%|████▉     | 395/792 [09:25<07:01,  1.06s/it, t_loss0=0.489, lr=1.73e-5, t_loss=0.883, v_loss=0.46, v_f1=0.971]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 13:59:21 [INFO] eps=1, lr=1.73e-05, t_loss=0.8832, v_loss=0.4597*, v_f1=0.9710*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:03<00:00,  1.55it/s]  1.08s/it, t_loss0=0.82, lr=1.17e-7, t_loss=0.883, v_loss=0.46, v_f1=0.971]   \n",
      "Epoch 1:  75%|███████▍  | 593/792 [14:05<03:34,  1.08s/it, t_loss0=0.82, lr=1.61e-5, t_loss=0.788, v_loss=0.438, v_f1=0.976]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 14:04:01 [INFO] eps=1, lr=1.61e-05, t_loss=0.7880, v_loss=0.4381*, v_f1=0.9761*\n",
      "11/19 14:04:04 [INFO] ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in1k-fold_idx=4-epoch=01-val_loss=0.4381-val_score=0.9761.ckpt : saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:08<00:00,  1.45it/s]  1.12s/it, t_loss0=0.48, lr=1.04e-7, t_loss=0.788, v_loss=0.438, v_f1=0.976]  \n",
      "Epoch 1: 100%|█████████▉| 791/792 [19:04<00:01,  1.12s/it, t_loss0=0.48, lr=1.5e-5, t_loss=0.73, v_loss=0.432, v_f1=0.976]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 14:09:00 [INFO] eps=1, lr=1.5e-05, t_loss=0.7304, v_loss=0.4325*, v_f1=0.9761 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 792/792 [19:04<00:00,  1.44s/it, t_loss0=0.48, lr=1.5e-5, t_loss=0.73, v_loss=0.432, v_f1=0.976]\n",
      "100%|██████████| 99/99 [01:03<00:00,  1.56it/s]  1.06s/it, t_loss0=0.372, lr=1.6e-7] \n",
      "Epoch 2:  25%|██▍       | 197/792 [04:43<10:28,  1.06s/it, t_loss0=0.372, lr=1.39e-5, t_loss=0.536, v_loss=0.432, v_f1=0.976]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 14:13:44 [INFO] eps=2, lr=1.39e-05, t_loss=0.5360, v_loss=0.4316*, v_f1=0.9756 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:03<00:00,  1.55it/s]  1.10s/it, t_loss0=0.662, lr=1.31e-7, t_loss=0.536, v_loss=0.432, v_f1=0.976]  \n",
      "Epoch 2:  50%|████▉     | 395/792 [09:26<07:16,  1.10s/it, t_loss0=0.662, lr=1.29e-5, t_loss=0.528, v_loss=0.424, v_f1=0.976]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 14:18:27 [INFO] eps=2, lr=1.29e-05, t_loss=0.5281, v_loss=0.4243*, v_f1=0.9763*\n",
      "11/19 14:18:30 [INFO] ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in1k-fold_idx=4-epoch=02-val_loss=0.4243-val_score=0.9763.ckpt : saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:12<00:00,  1.36it/s]  1.15s/it, t_loss0=0.661, lr=1.13e-7, t_loss=0.528, v_loss=0.424, v_f1=0.976]  \n",
      "Epoch 2:  75%|███████▍  | 593/792 [14:32<03:49,  1.15s/it, t_loss0=0.661, lr=1.2e-5, t_loss=0.524, v_loss=0.427, v_f1=0.976] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 14:23:33 [INFO] eps=2, lr=1.2e-05, t_loss=0.5238, v_loss=0.4269 , v_f1=0.9762 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:03<00:00,  1.57it/s]  1.15s/it, t_loss0=0.628, lr=1.03e-7, t_loss=0.524, v_loss=0.427, v_f1=0.976] \n",
      "Epoch 2: 100%|█████████▉| 791/792 [19:23<00:01,  1.15s/it, t_loss0=0.628, lr=1.12e-5, t_loss=0.525, v_loss=0.424, v_f1=0.979]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 14:28:24 [INFO] eps=2, lr=1.12e-05, t_loss=0.5255, v_loss=0.4242*, v_f1=0.9794*\n",
      "11/19 14:28:27 [INFO] ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in1k-fold_idx=4-epoch=02-val_loss=0.4242-val_score=0.9794.ckpt : saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 792/792 [19:26<00:00,  1.47s/it, t_loss0=0.628, lr=1.12e-5, t_loss=0.525, v_loss=0.424, v_f1=0.979]\n",
      "100%|██████████| 99/99 [01:04<00:00,  1.54it/s]  1.12s/it, t_loss0=0.724, lr=1.45e-7]\n",
      "Epoch 3:  25%|██▍       | 197/792 [04:47<11:07,  1.12s/it, t_loss0=0.724, lr=1.04e-5, t_loss=0.482, v_loss=0.419, v_f1=0.98]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 14:33:15 [INFO] eps=3, lr=1.04e-05, t_loss=0.4822, v_loss=0.4190*, v_f1=0.9801*\n",
      "11/19 14:33:18 [INFO] ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in1k-fold_idx=4-epoch=03-val_loss=0.4190-val_score=0.9801.ckpt : saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:03<00:00,  1.57it/s]  1.11s/it, t_loss0=0.488, lr=1.23e-7, t_loss=0.482, v_loss=0.419, v_f1=0.98]  \n",
      "Epoch 3:  50%|████▉     | 395/792 [09:38<07:20,  1.11s/it, t_loss0=0.488, lr=9.68e-6, t_loss=0.49, v_loss=0.415, v_f1=0.98] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 14:38:06 [INFO] eps=3, lr=9.68e-06, t_loss=0.4901, v_loss=0.4150*, v_f1=0.9797 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:04<00:00,  1.55it/s]  1.13s/it, t_loss0=0.377, lr=1.1e-7, t_loss=0.49, v_loss=0.415, v_f1=0.98]   \n",
      "Epoch 3:  75%|███████▍  | 593/792 [14:24<03:45,  1.13s/it, t_loss0=0.377, lr=9e-6, t_loss=0.484, v_loss=0.417, v_f1=0.978]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 14:42:52 [INFO] eps=3, lr=9e-06, t_loss=0.4840, v_loss=0.4169 , v_f1=0.9777 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:03<00:00,  1.56it/s]  1.10s/it, t_loss0=0.48, lr=1.02e-7, t_loss=0.484, v_loss=0.417, v_f1=0.978] \n",
      "Epoch 3: 100%|█████████▉| 791/792 [19:08<00:01,  1.10s/it, t_loss0=0.48, lr=8.37e-6, t_loss=0.482, v_loss=0.415, v_f1=0.98] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 14:47:36 [INFO] eps=3, lr=8.37e-06, t_loss=0.4824, v_loss=0.4153 , v_f1=0.9800 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 792/792 [19:08<00:00,  1.45s/it, t_loss0=0.48, lr=8.37e-6, t_loss=0.482, v_loss=0.415, v_f1=0.98]\n",
      "100%|██████████| 99/99 [01:03<00:00,  1.56it/s]  1.05s/it, t_loss0=0.617, lr=1.33e-7]\n",
      "Epoch 4:  25%|██▍       | 197/792 [04:40<10:27,  1.05s/it, t_loss0=0.617, lr=7.79e-6, t_loss=0.451, v_loss=0.416, v_f1=0.98]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 14:52:16 [INFO] eps=4, lr=7.79e-06, t_loss=0.4512, v_loss=0.4163 , v_f1=0.9797 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:03<00:00,  1.56it/s]  1.06s/it, t_loss0=0.522, lr=1.17e-7, t_loss=0.451, v_loss=0.416, v_f1=0.98]  \n",
      "Epoch 4:  50%|████▉     | 395/792 [09:20<07:01,  1.06s/it, t_loss0=0.522, lr=7.24e-6, t_loss=0.455, v_loss=0.41, v_f1=0.979]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 14:56:56 [INFO] eps=4, lr=7.24e-06, t_loss=0.4546, v_loss=0.4104*, v_f1=0.9795 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:03<00:00,  1.56it/s]  1.02s/it, t_loss0=0.356, lr=1.07e-7, t_loss=0.455, v_loss=0.41, v_f1=0.979]  \n",
      "Epoch 4:  75%|███████▍  | 593/792 [13:58<03:23,  1.02s/it, t_loss0=0.356, lr=6.73e-6, t_loss=0.459, v_loss=0.411, v_f1=0.98]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 15:01:34 [INFO] eps=4, lr=6.73e-06, t_loss=0.4590, v_loss=0.4109 , v_f1=0.9801 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:04<00:00,  1.54it/s]  1.06s/it, t_loss0=0.644, lr=1.02e-7, t_loss=0.459, v_loss=0.411, v_f1=0.98]  \n",
      "Epoch 4: 100%|█████████▉| 791/792 [18:38<00:01,  1.06s/it, t_loss0=0.644, lr=6.26e-6, t_loss=0.461, v_loss=0.41, v_f1=0.981]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 15:06:14 [INFO] eps=4, lr=6.26e-06, t_loss=0.4608, v_loss=0.4100*, v_f1=0.9813*\n",
      "11/19 15:06:16 [INFO] ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in1k-fold_idx=4-epoch=04-val_loss=0.4100-val_score=0.9813.ckpt : saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 792/792 [18:41<00:00,  1.42s/it, t_loss0=0.644, lr=6.26e-6, t_loss=0.461, v_loss=0.41, v_f1=0.981]\n",
      "100%|██████████| 99/99 [01:04<00:00,  1.54it/s]  1.10s/it, t_loss0=0.4, lr=1.25e-7]  \n",
      "Epoch 5:  25%|██▍       | 197/792 [04:39<10:55,  1.10s/it, t_loss0=0.4, lr=5.82e-6, t_loss=0.448, v_loss=0.409, v_f1=0.981]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 15:10:56 [INFO] eps=5, lr=5.82e-06, t_loss=0.4480, v_loss=0.4085*, v_f1=0.9810 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:04<00:00,  1.54it/s]  1.12s/it, t_loss0=0.341, lr=1.13e-7, t_loss=0.448, v_loss=0.409, v_f1=0.981]  \n",
      "Epoch 5:  50%|████▉     | 395/792 [09:20<07:23,  1.12s/it, t_loss0=0.341, lr=5.42e-6, t_loss=0.445, v_loss=0.409, v_f1=0.979]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 15:15:37 [INFO] eps=5, lr=5.42e-06, t_loss=0.4453, v_loss=0.4095 , v_f1=0.9791 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:04<00:00,  1.54it/s]  1.07s/it, t_loss0=0.369, lr=1.05e-7, t_loss=0.445, v_loss=0.409, v_f1=0.979]  \n",
      "Epoch 5:  75%|███████▍  | 593/792 [14:00<03:33,  1.07s/it, t_loss0=0.369, lr=5.04e-6, t_loss=0.444, v_loss=0.409, v_f1=0.982]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 15:20:17 [INFO] eps=5, lr=5.04e-06, t_loss=0.4443, v_loss=0.4086 , v_f1=0.9823*\n",
      "11/19 15:20:20 [INFO] ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in1k-fold_idx=4-epoch=05-val_loss=0.4086-val_score=0.9823.ckpt : saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:04<00:00,  1.54it/s]  1.11s/it, t_loss0=0.694, lr=1.01e-7, t_loss=0.444, v_loss=0.409, v_f1=0.982]  \n",
      "Epoch 5: 100%|█████████▉| 791/792 [18:43<00:01,  1.11s/it, t_loss0=0.694, lr=4.68e-6, t_loss=0.445, v_loss=0.409, v_f1=0.982]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 15:25:00 [INFO] eps=5, lr=4.68e-06, t_loss=0.4450, v_loss=0.4095 , v_f1=0.9818 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 792/792 [18:43<00:00,  1.42s/it, t_loss0=0.694, lr=4.68e-6, t_loss=0.445, v_loss=0.409, v_f1=0.982]\n",
      "100%|██████████| 99/99 [01:03<00:00,  1.56it/s]  1.12s/it, t_loss0=0.372, lr=1.18e-7]\n",
      "Epoch 6:  25%|██▍       | 197/792 [04:41<11:03,  1.12s/it, t_loss0=0.372, lr=4.36e-6, t_loss=0.459, v_loss=0.415, v_f1=0.981]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 15:29:41 [INFO] eps=6, lr=4.36e-06, t_loss=0.4594, v_loss=0.4145 , v_f1=0.9810 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:04<00:00,  1.55it/s]  1.13s/it, t_loss0=0.355, lr=1.1e-7, t_loss=0.459, v_loss=0.415, v_f1=0.981]   \n",
      "Epoch 6:  50%|████▉     | 395/792 [09:23<07:27,  1.13s/it, t_loss0=0.355, lr=4.05e-6, t_loss=0.447, v_loss=0.412, v_f1=0.981]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 15:34:23 [INFO] eps=6, lr=4.05e-06, t_loss=0.4473, v_loss=0.4120 , v_f1=0.9810 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:03<00:00,  1.55it/s]  1.06s/it, t_loss0=0.518, lr=1.04e-7, t_loss=0.447, v_loss=0.412, v_f1=0.981]  \n",
      "Epoch 6:  75%|███████▍  | 593/792 [14:04<03:30,  1.06s/it, t_loss0=0.518, lr=3.77e-6, t_loss=0.443, v_loss=0.414, v_f1=0.981]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 15:39:04 [INFO] eps=6, lr=3.77e-06, t_loss=0.4429, v_loss=0.4142 , v_f1=0.9810 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:03<00:00,  1.55it/s]  1.09s/it, t_loss0=0.466, lr=1.01e-7, t_loss=0.443, v_loss=0.414, v_f1=0.981]  \n",
      "Epoch 6: 100%|█████████▉| 791/792 [18:44<00:01,  1.09s/it, t_loss0=0.466, lr=3.5e-6, t_loss=0.443, v_loss=0.415, v_f1=0.983] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 15:43:44 [INFO] eps=6, lr=3.5e-06, t_loss=0.4432, v_loss=0.4153 , v_f1=0.9826*\n",
      "11/19 15:43:47 [INFO] ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in1k-fold_idx=4-epoch=06-val_loss=0.4153-val_score=0.9826.ckpt : saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 792/792 [18:47<00:00,  1.42s/it, t_loss0=0.466, lr=3.5e-6, t_loss=0.443, v_loss=0.415, v_f1=0.983]\n",
      "100%|██████████| 99/99 [01:06<00:00,  1.49it/s]  1.09s/it, t_loss0=0.48, lr=1.14e-7] \n",
      "Epoch 7:  25%|██▍       | 197/792 [04:45<10:46,  1.09s/it, t_loss0=0.48, lr=3.26e-6, t_loss=0.441, v_loss=0.414, v_f1=0.981]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 15:48:33 [INFO] eps=7, lr=3.26e-06, t_loss=0.4413, v_loss=0.4142 , v_f1=0.9813 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:03<00:00,  1.55it/s]  1.12s/it, t_loss0=0.355, lr=1.07e-7, t_loss=0.441, v_loss=0.414, v_f1=0.981]  \n",
      "Epoch 7:  50%|████▉     | 395/792 [09:29<07:24,  1.12s/it, t_loss0=0.355, lr=3.03e-6, t_loss=0.441, v_loss=0.41, v_f1=0.983] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 15:53:17 [INFO] eps=7, lr=3.03e-06, t_loss=0.4407, v_loss=0.4105 , v_f1=0.9830*\n",
      "11/19 15:53:20 [INFO] ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in1k-fold_idx=4-epoch=07-val_loss=0.4105-val_score=0.9830.ckpt : saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:04<00:00,  1.52it/s]  1.12s/it, t_loss0=0.348, lr=1.03e-7, t_loss=0.441, v_loss=0.41, v_f1=0.983]  \n",
      "Epoch 7:  75%|███████▍  | 593/792 [14:17<03:42,  1.12s/it, t_loss0=0.348, lr=2.82e-6, t_loss=0.438, v_loss=0.412, v_f1=0.982]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 15:58:05 [INFO] eps=7, lr=2.82e-06, t_loss=0.4376, v_loss=0.4116 , v_f1=0.9818 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:04<00:00,  1.53it/s]  1.14s/it, t_loss0=0.35, lr=1.01e-7, t_loss=0.438, v_loss=0.412, v_f1=0.982]   \n",
      "Epoch 7: 100%|█████████▉| 791/792 [19:02<00:01,  1.14s/it, t_loss0=0.35, lr=2.62e-6, t_loss=0.437, v_loss=0.411, v_f1=0.982]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 16:02:50 [INFO] eps=7, lr=2.62e-06, t_loss=0.4370, v_loss=0.4114 , v_f1=0.9824 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 792/792 [19:02<00:00,  1.44s/it, t_loss0=0.35, lr=2.62e-6, t_loss=0.437, v_loss=0.411, v_f1=0.982]\n",
      "100%|██████████| 99/99 [01:05<00:00,  1.52it/s]  1.10s/it, t_loss0=0.35, lr=1.1e-7]  \n",
      "Epoch 8:  25%|██▍       | 197/792 [04:42<10:54,  1.10s/it, t_loss0=0.35, lr=2.44e-6, t_loss=0.429, v_loss=0.411, v_f1=0.983]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 16:07:33 [INFO] eps=8, lr=2.44e-06, t_loss=0.4288, v_loss=0.4113 , v_f1=0.9828 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:04<00:00,  1.54it/s]  1.12s/it, t_loss0=0.355, lr=1.05e-7, t_loss=0.429, v_loss=0.411, v_f1=0.983]  \n",
      "Epoch 8:  50%|████▉     | 395/792 [09:24<07:23,  1.12s/it, t_loss0=0.355, lr=2.27e-6, t_loss=0.426, v_loss=0.409, v_f1=0.984]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 16:12:15 [INFO] eps=8, lr=2.27e-06, t_loss=0.4261, v_loss=0.4094 , v_f1=0.9837*\n",
      "11/19 16:12:18 [INFO] ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in1k-fold_idx=4-epoch=08-val_loss=0.4094-val_score=0.9837.ckpt : saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:03<00:00,  1.56it/s]  1.10s/it, t_loss0=0.353, lr=1.02e-7, t_loss=0.426, v_loss=0.409, v_f1=0.984]  \n",
      "Epoch 8:  75%|███████▍  | 593/792 [14:08<03:39,  1.10s/it, t_loss0=0.353, lr=2.11e-6, t_loss=0.427, v_loss=0.41, v_f1=0.984] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 16:16:59 [INFO] eps=8, lr=2.11e-06, t_loss=0.4266, v_loss=0.4095 , v_f1=0.9837 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:04<00:00,  1.54it/s]  1.08s/it, t_loss0=0.35, lr=1.01e-7, t_loss=0.427, v_loss=0.41, v_f1=0.984]   \n",
      "Epoch 8: 100%|█████████▉| 791/792 [18:47<00:01,  1.08s/it, t_loss0=0.35, lr=1.96e-6, t_loss=0.432, v_loss=0.41, v_f1=0.983]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 16:21:37 [INFO] eps=8, lr=1.96e-06, t_loss=0.4317, v_loss=0.4098 , v_f1=0.9827 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 792/792 [18:47<00:00,  1.42s/it, t_loss0=0.35, lr=1.96e-6, t_loss=0.432, v_loss=0.41, v_f1=0.983]\n",
      "100%|██████████| 99/99 [01:04<00:00,  1.53it/s]  1.08s/it, t_loss0=0.373, lr=1.07e-7]\n",
      "Epoch 9:  25%|██▍       | 197/792 [04:42<10:45,  1.08s/it, t_loss0=0.373, lr=1.82e-6, t_loss=0.429, v_loss=0.411, v_f1=0.983]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 16:26:20 [INFO] eps=9, lr=1.82e-06, t_loss=0.4294, v_loss=0.4110 , v_f1=0.9831 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:04<00:00,  1.53it/s]  1.13s/it, t_loss0=0.552, lr=1.04e-7, t_loss=0.429, v_loss=0.411, v_f1=0.983]  \n",
      "Epoch 9:  50%|████▉     | 395/792 [09:25<07:29,  1.13s/it, t_loss0=0.552, lr=1.7e-6, t_loss=0.43, v_loss=0.409, v_f1=0.984]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 16:31:03 [INFO] eps=9, lr=1.7e-06, t_loss=0.4296, v_loss=0.4093 , v_f1=0.9837*\n",
      "11/19 16:31:06 [INFO] ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in1k-fold_idx=4-epoch=09-val_loss=0.4093-val_score=0.9837.ckpt : saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:05<00:00,  1.52it/s]  1.12s/it, t_loss0=0.343, lr=1.02e-7, t_loss=0.43, v_loss=0.409, v_f1=0.984] \n",
      "Epoch 9:  75%|███████▍  | 593/792 [14:12<03:42,  1.12s/it, t_loss0=0.343, lr=1.58e-6, t_loss=0.432, v_loss=0.412, v_f1=0.983]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 16:35:50 [INFO] eps=9, lr=1.58e-06, t_loss=0.4320, v_loss=0.4116 , v_f1=0.9827 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:04<00:00,  1.53it/s]  1.08s/it, t_loss0=0.346, lr=1e-7, t_loss=0.432, v_loss=0.412, v_f1=0.983]     \n",
      "Epoch 9: 100%|█████████▉| 791/792 [18:55<00:01,  1.08s/it, t_loss0=0.346, lr=1.47e-6, t_loss=0.431, v_loss=0.411, v_f1=0.982]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 16:40:33 [INFO] eps=9, lr=1.47e-06, t_loss=0.4305, v_loss=0.4110 , v_f1=0.9825 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 792/792 [18:55<00:00,  1.43s/it, t_loss0=0.346, lr=1.47e-6, t_loss=0.431, v_loss=0.411, v_f1=0.982]\n",
      "100%|██████████| 99/99 [01:04<00:00,  1.53it/s],  1.09s/it, t_loss0=0.561, lr=1.05e-7]\n",
      "Epoch 10:  25%|██▍       | 197/792 [04:42<10:46,  1.09s/it, t_loss0=0.561, lr=1.36e-6, t_loss=0.415, v_loss=0.41, v_f1=0.983]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 16:45:15 [INFO] eps=10, lr=1.36e-06, t_loss=0.4148, v_loss=0.4100 , v_f1=0.9831 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:04<00:00,  1.54it/s],  1.08s/it, t_loss0=0.352, lr=1.03e-7, t_loss=0.415, v_loss=0.41, v_f1=0.983]  \n",
      "Epoch 10:  50%|████▉     | 395/792 [09:24<07:07,  1.08s/it, t_loss0=0.352, lr=1.27e-6, t_loss=0.418, v_loss=0.408, v_f1=0.984]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 16:49:57 [INFO] eps=10, lr=1.27e-06, t_loss=0.4179, v_loss=0.4084*, v_f1=0.9839*\n",
      "11/19 16:50:00 [INFO] ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in1k-fold_idx=4-epoch=10-val_loss=0.4084-val_score=0.9839.ckpt : saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:04<00:00,  1.53it/s],  1.07s/it, t_loss0=0.561, lr=1.01e-7, t_loss=0.418, v_loss=0.408, v_f1=0.984]  \n",
      "Epoch 10:  75%|███████▍  | 593/792 [14:11<03:33,  1.07s/it, t_loss0=0.561, lr=1.18e-6, t_loss=0.424, v_loss=0.411, v_f1=0.982]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 16:54:44 [INFO] eps=10, lr=1.18e-06, t_loss=0.4240, v_loss=0.4113 , v_f1=0.9824 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:04<00:00,  1.53it/s],  1.10s/it, t_loss0=0.36, lr=1e-7, t_loss=0.424, v_loss=0.411, v_f1=0.982]      \n",
      "Epoch 10: 100%|█████████▉| 791/792 [18:54<00:01,  1.10s/it, t_loss0=0.36, lr=1.1e-6, t_loss=0.423, v_loss=0.411, v_f1=0.983]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 16:59:28 [INFO] eps=10, lr=1.1e-06, t_loss=0.4231, v_loss=0.4114 , v_f1=0.9828 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 792/792 [18:54<00:00,  1.43s/it, t_loss0=0.36, lr=1.1e-6, t_loss=0.423, v_loss=0.411, v_f1=0.983]\n",
      "100%|██████████| 99/99 [01:05<00:00,  1.52it/s],  1.11s/it, t_loss0=0.35, lr=1.04e-7] \n",
      "Epoch 11:  25%|██▍       | 197/792 [04:43<10:59,  1.11s/it, t_loss0=0.35, lr=1.02e-6, t_loss=0.406, v_loss=0.412, v_f1=0.982]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 17:04:11 [INFO] eps=11, lr=1.02e-06, t_loss=0.4058, v_loss=0.4119 , v_f1=0.9825 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:05<00:00,  1.51it/s],  1.14s/it, t_loss0=0.353, lr=1.02e-7, t_loss=0.406, v_loss=0.412, v_f1=0.982]  \n",
      "Epoch 11:  50%|████▉     | 395/792 [09:27<07:31,  1.14s/it, t_loss0=0.353, lr=9.49e-7, t_loss=0.42, v_loss=0.411, v_f1=0.983] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 17:08:55 [INFO] eps=11, lr=9.49e-07, t_loss=0.4195, v_loss=0.4109 , v_f1=0.9831 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:05<00:00,  1.52it/s],  1.12s/it, t_loss0=0.422, lr=1.01e-7, t_loss=0.42, v_loss=0.411, v_f1=0.983]  \n",
      "Epoch 11:  75%|███████▍  | 593/792 [14:12<03:43,  1.12s/it, t_loss0=0.422, lr=8.83e-7, t_loss=0.419, v_loss=0.411, v_f1=0.983]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 17:13:40 [INFO] eps=11, lr=8.83e-07, t_loss=0.4192, v_loss=0.4111 , v_f1=0.9825 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:05<00:00,  1.52it/s],  1.12s/it, t_loss0=0.577, lr=1e-7, t_loss=0.419, v_loss=0.411, v_f1=0.983]     \n",
      "Epoch 11: 100%|█████████▉| 791/792 [18:56<00:01,  1.12s/it, t_loss0=0.577, lr=8.21e-7, t_loss=0.419, v_loss=0.412, v_f1=0.982]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 17:18:24 [INFO] eps=11, lr=8.21e-07, t_loss=0.4190, v_loss=0.4115 , v_f1=0.9824 \n",
      "11/19 17:18:24 [INFO] NO_MORE_TRAINING, best_score=0.9839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:05<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 17:19:30 [INFO] EMA ::: ema_v_loss=0.4095, ema_v_f1=0.9830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 17:19:33 [INFO] ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in1k-fold_idx=4-epoch=11-val_loss=0.4095-val_score=0.9830-ema.ckpt : (ema) saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|█████████▉| 791/792 [20:05<00:01,  1.52s/it, t_loss0=0.577, lr=8.21e-7, t_loss=0.419, v_loss=0.412, v_f1=0.982]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 17:19:34 [INFO] fold_idx=4 finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>ema_v_f1</td><td>▁</td></tr><tr><td>ema_v_loss</td><td>▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▂▃▃▃▄▄▅▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█</td></tr><tr><td>lr</td><td>█▄▆▃▂▅▄▄▅▁▄▂▁▂▁▁▂▁▁▁▁▁▂▁▂▁▁▁▁▂▁▁▂▁▁▁▁▁▁▁</td></tr><tr><td>step</td><td>▅▅▆▆▆█▃▅▆▆▃▂▄▄▁▂▃▅▆▆▂▃▅▅▂▃▅▃▅▇█▁▃▃▆▃▄▅▆▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>ema_v_f1</td><td>0.98304</td></tr><tr><td>ema_v_loss</td><td>0.40949</td></tr><tr><td>epoch</td><td>11</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>step</td><td>792</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /home/gooruem/Competition/BIRD/dacon2024_bird_lowres_image_classification/wandb/offline-run-20241119_134953-4s71okj0<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20241119_134953-4s71okj0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: can't open file '/home/gooruem/send_telegram.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "dt_str = datetime.now().strftime('%m%d%H%M')\n",
    "\n",
    "for fold_idx, (train_index, val_index) in enumerate(skf.split(train_df, train_df['class'])):\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    logger.info(f'{fold_idx=} started')\n",
    "    import wandb\n",
    "    run = wandb.init(\n",
    "        name=f'fold{fold_idx+1}_{CFG[\"MODEL_NAME\"].split(\"/\")[1].split(\"-\")[0]}_{dt_str}',\n",
    "        config=CFG,\n",
    "        reinit=True)\n",
    "    \n",
    "    train_fold_df = train_df.loc[train_index,:]\n",
    "    val_fold_df = train_df.loc[val_index,:]\n",
    "\n",
    "    train_dataset = CustomDataset( \n",
    "        train_fold_df['img_path'].values, train_fold_df['class'].values, \n",
    "        interpolation=CFG['INTERPOLATION'], load_img_size=CFG['IMG_TRAIN_SIZE'],\n",
    "        shuffle=True, transforms=train_transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, generator=torch.Generator(device=device), num_workers=0)\n",
    "    val_dataset = CustomDataset(\n",
    "        val_fold_df['img_path'].values,\n",
    "        val_fold_df['class'].values,\n",
    "        interpolation=CFG['INTERPOLATION'], load_img_size=CFG['IMG_SIZE'],\n",
    "        shuffle=False, transforms=test_transform)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE']*2, shuffle=False, generator=torch.Generator(device=device), num_workers=0)\n",
    "\n",
    "    model = create_model(CFG['MODEL_NAME'])\n",
    "    \n",
    "    ## wrapp model\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=CFG['LR'][0],\n",
    "        weight_decay=0.001,  ## default는 0.01이며, 논문은 0.001임.\n",
    "    )\n",
    "    scheduler = None\n",
    "    scheduler = CosineAnnealingWarmupRestarts(\n",
    "        optimizer,\n",
    "        first_cycle_steps=int( len(train_loader) ) // 4,\n",
    "        cycle_mult=1.0, max_lr=CFG['LR'][0] * 2, \n",
    "        min_lr=CFG['LR'][1],\n",
    "        warmup_steps=0, \n",
    "        gamma=0.93,  ## 2024.05.02\n",
    "    )\n",
    "    \n",
    "    model = train( \n",
    "        model, optimizer, train_loader, val_loader, scheduler, device,\n",
    "        use_amp=(CFG['PRECISION'] == '16'),\n",
    "        filename = f'./ckpt/{CFG[\"MODEL_NAME\"].split(\"/\")[1].split(\"-\")[0]}-fold_idx={fold_idx}-' + 'epoch={epoch:02d}-val_loss={val_loss:.4f}-val_score={val_score:.4f}',\n",
    "    )\n",
    "    \n",
    "    model = None\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    logger.info(f'{fold_idx=} finished')\n",
    "    run.finish()\n",
    "    \n",
    "    try:\n",
    "        # !python ~/send_telegram.py 'fold_idx={fold_idx} finished'\n",
    "        last_chpt_info = !ls -t ./ckpt/ | head -n1\n",
    "        last_chpt_info = ','.join( last_chpt_info[0][:-5].split('-')[1:] )\n",
    "        !python ~/send_telegram.py {last_chpt_info}\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 앙상블 및 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                               ./ckpt/fold_4.ckpt.ckpt\n",
      "1     ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in...\n",
      "2     ./ckpt/eva_large_patch14_196.in22k_ft_in22k_in...\n",
      "3     ./ckpt/deit3_large_patch16_224.fb_in22k_ft_in1...\n",
      "4                               ./ckpt/fold_2.ckpt.ckpt\n",
      "5     ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in...\n",
      "6     ./ckpt/deit3_large_patch16_224.fb_in22k_ft_in1...\n",
      "7     ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in...\n",
      "8     ./ckpt/deit3_large_patch16_224.fb_in22k_ft_in1...\n",
      "9     ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in...\n",
      "10    ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in...\n",
      "11    ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in...\n",
      "12    ./ckpt/deit3_large_patch16_224.fb_in22k_ft_in1...\n",
      "13    ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in...\n",
      "14    ./ckpt/deit3_large_patch16_224.fb_in22k_ft_in1...\n",
      "15    ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in...\n",
      "16    ./ckpt/eva_large_patch14_196.in22k_ft_in22k_in...\n",
      "17    ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in...\n",
      "18    ./ckpt/deit3_large_patch16_224.fb_in22k_ft_in1...\n",
      "19    ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in...\n",
      "20                              ./ckpt/fold_3.ckpt.ckpt\n",
      "21    ./ckpt/eva_large_patch14_196.in22k_ft_in22k_in...\n",
      "22    ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in...\n",
      "23    ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in...\n",
      "24                              ./ckpt/fold_1.ckpt.ckpt\n",
      "25    ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in...\n",
      "26                                   ./ckpt/fold_0.ckpt\n",
      "27    ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in...\n",
      "28    ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in...\n",
      "29    ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in...\n",
      "30    ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in...\n",
      "31    ./ckpt/deit3_large_patch16_224.fb_in22k_ft_in1...\n",
      "32    ./ckpt/deit3_large_patch16_224.fb_in22k_ft_in1...\n",
      "33    ./ckpt/deit3_large_patch16_224.fb_in22k_ft_in1...\n",
      "34    ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in...\n",
      "35    ./ckpt/deit3_large_patch16_224.fb_in22k_ft_in1...\n",
      "36    ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in...\n",
      "37    ./ckpt/deit3_large_patch16_224.fb_in22k_ft_in1...\n",
      "38    ./ckpt/eva_large_patch14_196.in22k_ft_in22k_in...\n",
      "39    ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in...\n",
      "40    ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in...\n",
      "41    ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in...\n",
      "42    ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in...\n",
      "Name: fname, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "ckpt_df = pd.DataFrame({'fname':glob('./ckpt/*.ckpt')})\n",
    "print(ckpt_df['fname'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "ckpt_df = pd.DataFrame({'fname':glob('./ckpt/*.ckpt')})\n",
    "ckpt_df['mtime'] = ckpt_df.fname.apply(lambda x: int(os.stat(x).st_mtime))\n",
    "ckpt_df['model_name'] = ckpt_df.fname.apply(lambda x: re.search(r'./ckpt/(.*?)-fold',x)[1])\n",
    "ckpt_df['img_size'] = ckpt_df.fname.apply(lambda x: int(re.search(r'patch[0-9]+_([0-9]+)', x + 'patch0_0')[1]) )\n",
    "ckpt_df['is_ema'] = ckpt_df.fname.str.endswith('ema.ckpt').astype(int)\n",
    "ckpt_df['fold_idx'] = ckpt_df.fname.apply(lambda x: int(re.search(r'fold_idx=([0-9])-',x)[1]))\n",
    "ckpt_df['val_loss'] = ckpt_df.fname.apply(lambda x: float(re.search(r'val_loss=(0\\.[0-9]+)', x)[1]) )\n",
    "ckpt_df['val_score'] = ckpt_df.fname.apply(lambda x: float(re.search(r'val_score=(0\\.[0-9]+)', x)[1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_model_name(x):\n",
    "    match = re.search(r'./ckpt/(.*?)-fold', x)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        print(f\"No match for filename: {x}\")\n",
    "        return 'unknown'\n",
    "\n",
    "ckpt_df['model_name'] = ckpt_df.fname.apply(extract_model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_df = ckpt_df[ckpt_df.img_size != 0][ckpt_df.is_ema == 0]\n",
    "ckpt_df = ckpt_df.sort_values('mtime',ascending=False).reset_index(drop=True)\n",
    "ckpt_indexes = ckpt_df[ ckpt_df.fold_idx==ckpt_df.fold_idx.max() ].index[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = []\n",
    "# preds_score = []\n",
    "\n",
    "# for ckpt_start_index in ckpt_indexes:\n",
    "#     logger.info(f'{ckpt_df.fname[ckpt_start_index]} loading')\n",
    "#     ## imagesize\n",
    "#     CFG['IMG_SIZE'] = ckpt_df.img_size[ckpt_start_index]\n",
    "#     assert CFG['IMG_SIZE'] in ( 196, 224, 336)\n",
    "#     logger.info(CFG['IMG_SIZE'])\n",
    "\n",
    "#     test_dataset = CustomDataset(\n",
    "#         test_df['img_path'].values, None, \n",
    "#         interpolation=CFG['INTERPOLATION'], load_img_size=CFG['IMG_SIZE'],\n",
    "#         shuffle=False, transforms=test_transform)\n",
    "#     test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE']*2, shuffle=False, num_workers=0)\n",
    "\n",
    "#     model_name = ckpt_df.model_name[ckpt_start_index]\n",
    "#     model = create_model(model_name)\n",
    "#     if ckpt_df.is_ema[ckpt_start_index]:\n",
    "#         model = torch.optim.swa_utils.AveragedModel(model)\n",
    "#     #-----------------------------\n",
    "#     for i in range(ckpt_start_index, ckpt_start_index + ckpt_df.fold_idx.max() + 1 ):\n",
    "#         checkpoint_path = ckpt_df.fname[i]\n",
    "#         logger.info(f'{checkpoint_path} loading')\n",
    "#         model.load_state_dict( torch.load(checkpoint_path)['model'] )\n",
    "        \n",
    "#         preds_score.append( ckpt_df.val_score[i] )\n",
    "#         preds.append( prediction(model, test_loader, device) )\n",
    "    \n",
    "# preds = np.array(preds)\n",
    "# preds_score = np.array(preds_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ### 가중치 평균값..\n",
    "# preds_error = (1-preds_score)  ## L1 ACC 오차인경우\n",
    "# preds_error = 1-preds_error/preds_error.sum()\n",
    "# preds_coef = preds_error/preds_error.sum()\n",
    "\n",
    "# logger.info(f'{preds_score=}')\n",
    "# logger.info(f'{preds_coef=}')\n",
    "# preds2 = np.array( [ coef * preds[i] for i, coef in enumerate( preds_coef ) ] )\n",
    "# preds_labels = le.inverse_transform(preds2.sum(0).argmax(-1))\n",
    "# print(preds_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit = pd.read_csv('./sample_submission.csv')\n",
    "# submit['label'] = preds_labels\n",
    "# from datetime import datetime\n",
    "# dt_str = datetime.now().strftime('%Y%m%d_%H%M')\n",
    "# submit.to_csv(f'./basslibrary_submit_{dt_str}.csv', index=False)\n",
    "# logger.info(f'./basslibrary_submit_{dt_str}.csv saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "RZo9oMpITxaP"
   },
   "outputs": [],
   "source": [
    "# !python ~/send_telegram.py 'basslibrary_submit_{dt_str}.csv saved'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/19 22:47:50 [INFO] ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in1k-fold_idx=4-epoch=10-val_loss=0.4084-val_score=0.9839.ckpt loading\n",
      "11/19 22:47:50 [INFO] 336\n",
      "11/19 22:47:50 [INFO] load_img_size=336\n",
      "11/19 22:47:50 [INFO] create_model: eva_large_patch14_336.in22k_ft_in22k_in1k\n",
      "11/19 22:47:50 [INFO] Loading pretrained weights from Hugging Face hub (timm/eva_large_patch14_336.in22k_ft_in22k_in1k)\n",
      "11/19 22:47:51 [INFO] [timm/eva_large_patch14_336.in22k_ft_in22k_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "11/19 22:47:52 [INFO] ./ckpt/eva_large_patch14_336.in22k_ft_in22k_in1k-fold_idx=4-epoch=10-val_loss=0.4084-val_score=0.9839.ckpt loading\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_181389/3374075125.py:47: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path)['model'])\n",
      "  0%|          | 0/213 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "import ttach as tta\n",
    "\n",
    "# tta_ = tta.Compose(\n",
    "#     [\n",
    "#       tta.HorizontalFlip(),\n",
    "#       tta.Multiply(factors=[0.9, 1, 1.1])\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "tta_ = tta.Compose(\n",
    "    [\n",
    "        tta.HorizontalFlip(),                     # 좌우 반전\n",
    "        tta.Rotate90(angles=[0, 90, 180, 270]),   # 90도 단위 회전\n",
    "        tta.Multiply(factors=[0.9, 1, 1.1]),      # 밝기 조정\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "preds = []\n",
    "preds_score = []\n",
    "\n",
    "for ckpt_start_index in ckpt_indexes:\n",
    "    logger.info(f'{ckpt_df.fname[ckpt_start_index]} loading')\n",
    "    # Image Size 설정\n",
    "    CFG['IMG_SIZE'] = ckpt_df.img_size[ckpt_start_index]\n",
    "    assert CFG['IMG_SIZE'] in ( 196, 224, 336)\n",
    "    logger.info(CFG['IMG_SIZE'])\n",
    "\n",
    "    # 테스트 데이터셋 및 로더 생성\n",
    "    test_dataset = CustomDataset(\n",
    "        test_df['img_path'].values, None,\n",
    "        interpolation=CFG['INTERPOLATION'], load_img_size=CFG['IMG_SIZE'],\n",
    "        shuffle=False, transforms=test_transform\n",
    "    )\n",
    "    test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'] * 2, shuffle=False, num_workers=0)\n",
    "\n",
    "    # 모델 생성 및 EMA 적용 여부 확인\n",
    "    model_name = ckpt_df.model_name[ckpt_start_index]\n",
    "    model = create_model(model_name)\n",
    "    if ckpt_df.is_ema[ckpt_start_index]:\n",
    "        model = torch.optim.swa_utils.AveragedModel(model)\n",
    "    \n",
    "    # 체크포인트 로드 및 TTA Wrapper 적용\n",
    "    for i in range(ckpt_start_index, ckpt_start_index + ckpt_df.fold_idx.max() + 1):\n",
    "        checkpoint_path = ckpt_df.fname[i]\n",
    "        logger.info(f'{checkpoint_path} loading')\n",
    "        model.load_state_dict(torch.load(checkpoint_path)['model'])\n",
    "\n",
    "        # TTA Wrapper로 모델 래핑\n",
    "        tta_model = tta.ClassificationTTAWrapper(model, tta_)\n",
    "\n",
    "        # TTA를 적용한 예측 수행\n",
    "        preds_score.append(ckpt_df.val_score[i])\n",
    "        preds.append(prediction(tta_model, test_loader, device))\n",
    "        \n",
    "\n",
    "\n",
    "# 결과 배열로 변환\n",
    "preds = np.array(preds)\n",
    "preds_score = np.array(preds_score)\n",
    "\n",
    "# 가중치 평균 계산\n",
    "preds_error = (1 - preds_score)  # L1 ACC 오차인 경우\n",
    "preds_error = 1 - preds_error / preds_error.sum()\n",
    "preds_coef = preds_error / preds_error.sum()\n",
    "\n",
    "logger.info(f'{preds_score=}')\n",
    "logger.info(f'{preds_coef=}')\n",
    "preds2 = np.array([coef * preds[i] for i, coef in enumerate(preds_coef)])\n",
    "preds_labels = le.inverse_transform(preds2.sum(0).argmax(-1))\n",
    "print(preds_labels)\n",
    "\n",
    "# 제출 파일 생성\n",
    "submit = pd.read_csv('./sample_submission.csv')\n",
    "submit['label'] = preds_labels\n",
    "from datetime import datetime\n",
    "dt_str = datetime.now().strftime('%Y%m%d_%H%M')\n",
    "submit.to_csv(f'./basslibrary_submit_{dt_str}.csv', index=False)\n",
    "logger.info(f'./basslibrary_submit_{dt_str}.csv saved')\n",
    "\n",
    "# 레이블 분포 출력\n",
    "submit.label.value_counts()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "BIRD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
